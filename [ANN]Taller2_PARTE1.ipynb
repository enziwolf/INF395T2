{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[ANN]Taller2_PARTE1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "D8F9gGetIX4O"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enziwolf/INF395T2/blob/master/%5BANN%5DTaller2_PARTE1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5rfZ_hYaQ1Z",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"30%\" />\n",
        "\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "<h1 align='center'> INF-395/477 Redes Neuronales Artificiales I-2020 </h1>\n",
        "\n",
        "<H3 align='center'> Tarea 2 - Redes Neuronales Convolucionales y Recurrentes </H3>\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "\n",
        "**Temas**  \n",
        "\n",
        "* Entrenamiento de Redes Neuronales Profundas. \n",
        "* Modelos de Auto-Encoder\n",
        "* Redes Convolucionales y Recurrentes. \n",
        "\n",
        "**Formalidades**  \n",
        "* Equipos de trabajo de: 3 personas (*cada uno debe estar en condiciones de realizar una presentación y discutir sobre cada punto del trabajo realizado*)\n",
        "* Formato de entrega: envı́o de link Github y link de video Youtube o plataforma a convenir, todo esto vía Aula. \n",
        "\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "\n",
        "### **Propuesta**\n",
        "* Se debe preparar una presentación de **15 a 20 minutos** donde se explique el cómo se va a realizar/resolver el taller, la metodología o propuesta de las componentes a experimentar y explorar. Más detalles en el Syllabus.\n",
        "* Fecha de encuentro Zoom: 12 de Junio en horario de clases.\n",
        "* Fecha de entrega de vídeo: Opcional para quienes presentaron y obligatorio para quienes no, a lo más 2 días después del encuentro.\n",
        "* Modalidad de Presentación (Zoom): En el primer bloque, se formarán 3 grupos para que alcancen a recibir feedback todos los equipos. En el segundo bloque, algunos equipos seleccionados presentarán a todo el curso. \n",
        "\n",
        "**Aún si la idea es aprender colaborativamente, valoraremos mucho la diversidad de ideas, por lo que las propuesta debiesen conservar su orientación inicial, excepto por el feedback que les entreguemos**\n",
        "\n",
        "### **Defensa**\n",
        "* Se debe preparar una presentación de **15 a 20 minutos** con los resultados obtenidos y conclusiones de la experiencia. \n",
        "* Se debe entregar el código, de preferencia en un (breve) Jupyter/IPython notebook, de modo que **permita reproducir los resultados** presentados. Si se entrega el código fuente se deben proveer instrucciones para su uso.\n",
        "* Fecha de encuentro Zoom: 26 de Junio, horario de clases.\n",
        "* Fecha de entrega de vídeo: 2 días antes de encuentro.\n",
        "* Fecha de entrega de Jypter (notebook): commits hasta 2 días antes del encuentro. \n",
        "* Modalidad de Presentación (Zoom): En ambos bloques algunos equipos seleccionados presentarán ante todo el curso, discusión y debate se generará en base a los resultados.\n",
        "\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "\n",
        "La tarea se divide en secciones:\n",
        "\n",
        "[1.](#primero) Pregunta Libre   \n",
        "[2.](#segundo) Challenge Kaggle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTkbRyusPMok",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"primero\"></a>\n",
        "## 1. Pregunta Libre\n",
        "\n",
        "Refute o evidencie experimentalmente una de las siguientes afirmaciones \n",
        "\n",
        "\n",
        "> Tema 1. Un autoencoder simétrico (la arquitectura del encoder es espejo del encoder) es más efectivo para aprender una representación que un autoencoder asimétrico Esto vale tanto para arquitecturas densas como convolucionales. \n",
        "\n",
        "> Tema 2. Un denoising autoencoder (DAE) logra la misma robustez de representación que un autoencoder variacional (VAE).\n",
        "\n",
        "> Tema 3. Usando etiquetas, es posible mejorar significativamente la calidad de las representaciones aprendidas por un autoencoder, aún si se dispone de un pequeño porcentaje de datos con ellas. \n",
        "\n",
        "> Tema 4. Regularizar un autoencoder para obtener representaciones *sparse* (dispersas) permite mejorar la calidad de las representaciones obtenidas para datos que no están en el conjunto de entrenamiento. \n",
        "\n",
        "> Tema 5. Una arquitectura con encoder profundo y decoder no profundo (1 capa) es más efectiva que una con decoder profundo y encoder no profundo (1 capa). Esto vale tanto para arquitecturas densas como convolucionales. \n",
        "\n",
        "> Tema 6. En un VAE, modificar el regularizador, KL(q(z|x)|p(z)), para que sea simétrico, no tiene ningún efecto práctico sobre la representación aprendida.\n",
        "\n",
        "> Tema 7. Organizando adecuadamente las capas, *Dropout* es mucho más efectivo que *BatchNormalization* para regularizar redes convolucionales profundas y juntos no funcionan muy bien. \n",
        "\n",
        "> Tema 8.  Los optimizadores más populares en deep learning (*AdaGrad, RMSProp, Adam* y *Nadam*) funcionan mejor que un simple SGD porque evitan que la red caiga en óptimos locales con alto error de predicción. \n",
        "\n",
        "> Tema 9. *BatchNormalization* facilita el entrenamiento de una red porque reduce el covariate shift interno y estabiliza la magnitud de los gradientes.  \n",
        "\n",
        "> Tema 10. Una red *LSTM* ó *GRU* permite aprender dependencias de mucho más largo plazo y más eficientemente que una red recurrente tipo *Elman*.\n",
        "\n",
        "> Tema 11. En un problema en que hay dependencias temporales de largo plazo, una red recurrente *bidireccional* será siempre más efectiva que una red *uni-direccional*. \n",
        "\n",
        "> Tema 12. Una red recurrente es un modelo más efectivo para predicción de *series de tiempo* que un modelo auto-regresivo denso (feed-forward).\n",
        "\n",
        "> Tema 13. No tiene sentido usar una red convolucional para aprendizaje de secuencias, su error será siempre mayor que el de una red recurrente.\n",
        "\n",
        "> Tema 14. En predicción de series de tiempo con redes recurrentes, *Dropout* permite obtener intervalos de confianza para la predicción que cubren bien el valor real.\n",
        "\n",
        "> Tema 15. En un problema de apredizaje seq-2-seq, una red recurrente con mecanismos atencionales será siempre más efectiva que una arquitectura recurrente encoder-decoder sin atención.\n",
        "\n",
        "> Tema 16. Al resolver un problema de apredizaje seq-2-seq, una encoder recurrente no tiene ventajas sobre un encoder convolucional si se utilizan mecanismos atencionales en el decoder.\n",
        "\n",
        "**Reglas mínimas**: Validar en al menos 1 dataset sintético y 2 reales.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOVjX4ZepbJa",
        "colab_type": "text"
      },
      "source": [
        "# Integrantes\n",
        "<center><p>Gabriel Ortega  </p>\n",
        "<p> Benjamín Riquelme</p> \n",
        "<p> Gabriel Araya</p> </center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsmPqlky_Tjf",
        "colab_type": "text"
      },
      "source": [
        "# <u>Tema 15</u>\n",
        "\n",
        "En un problema de apredizaje seq-2-seq, una red recurrente con mecanismos atencionales será siempre más efectiva que una arquitectura recurrente encoder-decoder sin atención. \n",
        "\n",
        "## <u>Preámbulo</u>\n",
        "\n",
        "### <u>Seq2Seq</u> \n",
        "\n",
        "Es un tipo de problema que consiste en transformar una secuencia en otra. Algunas de sus aplicaciones son: traducción de texto, resumir texto, modelos conversacionales, etc. \n",
        "\n",
        "### <u>Red Recurrente</u>\n",
        "\n",
        "Es una arquitectura de red neuronal que se especializa en el análisis de secuencias. Tiene dos partes principales, un encoder que recibe los datos de entrada y cambia su representación. Esta representación se pasa a la segunda parte, un decoder, que intenta decodificar la secuencia de salida a partir de lo entregado por el encoder.\n",
        "\n",
        "La siguiente imagen muestra un diagrama simple de una red recurrente.\n",
        "\n",
        "<img src=\"https://i.imgur.com/jf0afOr.png\" height=\"250px\">\n",
        "\n",
        "\n",
        "### <u>Mecanismo de Atención</u>\n",
        "\n",
        "Modelos de RNN como LSTM y GRU eran bastante exitosos. Sin embargo, cuando se enfrentaban a tareas de inputs muy largos su desempeño podía ser mucho mejor. Debido a esto es que se implementó un mecanismo auxiliar para ayudar a las redes recurrentes y es la **atención**.\n",
        "\n",
        "Lo que hace el mecanismo de atención es crear un vector de contexto a partir de los estados del decoder y la representación del encoder. Este mecanismo tiene una capa softmax de salida ya que así filtra el vector de contexto en componentes importantes y no importantes. Por ejemplo, si en el paso actual interesan los datos en las posiciones 2 y 3, pero no la posición 1, entonces la capa softmax debería darle un valor cercano a cero al primer vector y un valor mayor a los otros dos vectores.\n",
        "\n",
        "La siguiente imagen muestra un diagrama simple de una RNN con atención:\n",
        "\n",
        "<img src=\"https://i.imgur.com/kCVjS6J.png\" height=\"300px\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v5IxLNpqmEu",
        "colab_type": "text"
      },
      "source": [
        "# <u>Datasets Sintéticos</u>\n",
        "\n",
        "En esta sección se crearán dos datasets sintéticos, uno en la categoría many to many que será un inversor de secuencias. Dada una secuencia $a_{1}, a_{2} ... a_{n}$ el output debe ser $a_{n},a_{n-1}....a{1}$.\n",
        "\n",
        "El segundo dataset sintético está en la categoría many to one, consistirá en clasificar una secuencia numérica como creciente o no creciente. Se dirá que una secuencia es creciente si se cumple lo siguiente:\n",
        "\n",
        "$$\n",
        "a_{i-1} \\leq a_{i} \\forall i \\in [2,N]\n",
        "$$\n",
        "\n",
        "Donde $N$ es el largo de la secuencia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TaFuOPKe9c-",
        "colab_type": "text"
      },
      "source": [
        "## Inversor de secuencia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00I8CthbdRJ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "44d73a99-39d1-4f2e-a41c-3351281737a8"
      },
      "source": [
        "# Bloque de imports\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import GRU\n",
        "from keras.layers import Dense\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import RepeatVector\n",
        "import numpy as np\n",
        "from random import randint as rint\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras import regularizers, constraints, initializers, activations\n",
        "from keras.layers.recurrent import Recurrent\n",
        "from keras.engine import InputSpec\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0PWQ6qg42cL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "cf2a0101-f48a-4131-c9ea-32f5abfbfcb9"
      },
      "source": [
        "import numpy as np\n",
        "from random import randint as rint\n",
        "\n",
        "def generate_sequence(total,unique):\n",
        "    #tiene que retornar una lista por eso la compresión\n",
        "    return [x for x in np.random.choice(a=unique,size=total,replace=False)]\n",
        "\n",
        "def oh_encode(secuencia,unique):\n",
        "    '''\n",
        "    Crea N vectores de largo unique\n",
        "    para cada elemento de la secuencia (N en total)\n",
        "    al vector correspondiente le pone el valor 1 en la posicion del elemento\n",
        "    seq = [2,3], largo 2 pero digamos que se hizo de 5 elem unicos\n",
        "    output:  [[0,0,1,0,0]\n",
        "              [0,0,0,1,0]]\n",
        "    '''\n",
        "    encoding = list()\n",
        "    for valor in secuencia:\n",
        "        vector = [0 for _ in range(unique)]\n",
        "        vector[valor] = 1\n",
        "        encoding.append(vector)\n",
        "    return np.array(encoding)\n",
        "\n",
        "def oh_decode(encoded):\n",
        "    return [np.argmax(vector) for vector in encoded]\n",
        "\n",
        "\n",
        "def generar_pares(largo,unique):\n",
        "    secuencia = generate_sequence(largo,unique)\n",
        "    x = oh_encode(secuencia,unique)\n",
        "    secuencia.reverse()\n",
        "    y = oh_encode(secuencia,unique)\n",
        "    # reshape as 3D\n",
        "    x = x.reshape((1, x.shape[0], x.shape[1])) #Reshape a: samples, timesteps, n_features\n",
        "    y = y.reshape((1, y.shape[0], y.shape[1]))\n",
        "    return x,y,secuencia\n",
        "\n",
        "\n",
        "def generate_dataset(largo,unique,n_rows):\n",
        "    dataset_x = list()\n",
        "    dataset_y = list()\n",
        "    secuencias_raw = list()\n",
        "    for _ in range(n_rows):\n",
        "        x,y,sec = generar_pares(largo,unique)\n",
        "        dataset_x.append(x)\n",
        "        dataset_y.append(y)\n",
        "        secuencias_raw.append(sec)\n",
        "    unique_data = [list(x) for x in set(tuple(x) for x in secuencias_raw)]\n",
        "    stackx = np.vstack(tuple(dataset_x))\n",
        "    stacky = np.vstack(tuple(dataset_y))\n",
        "\n",
        "    return stackx, stacky,unique_data\n",
        "\n",
        "def split_dataset(X,Y,n_rows,p,semilla=0):\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "    x_test = []\n",
        "    y_test = []\n",
        "\n",
        "    np.random.seed(semilla)\n",
        "\n",
        "    indices = np.random.choice(n_rows,size=int(p*n_rows),replace=False)\n",
        "    for i in range(n_rows):\n",
        "        if i in indices:\n",
        "            x_test.append(X[i])\n",
        "            y_test.append(Y[i])\n",
        "        else:\n",
        "            x_train.append(X[i])\n",
        "            y_train.append(Y[i])\n",
        "            \n",
        "    return np.array(x_train),np.array(y_train),np.array(x_test),np.array(y_test)\n",
        "\n",
        "\n",
        "##Crear Datasets de largo distinto\n",
        "\n",
        "seq_length = 5\n",
        "n_unique = 100 #aumentar esto acorde a rows para asegurar probabilisticamente tener 'rows' secuencias distintas\n",
        "rows = 5000\n",
        "\n",
        "X_dataset5,Y_dataset5,seq_set = generate_dataset(seq_length,n_unique,rows)\n",
        "print(\"X:\",X_dataset5.shape,\"Y:\",Y_dataset5.shape)\n",
        "print(\"Secuencias unicas logradas:\",len(seq_set),\"de:\",rows)\n",
        "\n",
        "\n",
        "\n",
        "seq_length = 30\n",
        "n_unique = 100 #aumentar esto acorde a rows para asegurar probabilisticamente tener 'rows' secuencias distintas\n",
        "rows = 5000\n",
        "\n",
        "X_dataset30,Y_dataset30,seq_set = generate_dataset(seq_length,n_unique,rows)\n",
        "print(\"X:\",X_dataset30.shape,\"Y:\",Y_dataset30.shape)\n",
        "print(\"Secuencias unicas logradas:\",len(seq_set),\"de:\",rows)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "seq_length = 50\n",
        "n_unique = 100 #aumentar esto acorde a rows para asegurar probabilisticamente tener 'rows' secuencias distintas\n",
        "rows = 5000\n",
        "\n",
        "X_dataset50,Y_dataset50,seq_set = generate_dataset(seq_length,n_unique,rows)\n",
        "print(\"X:\",X_dataset50.shape,\"Y:\",Y_dataset50.shape)\n",
        "print(\"Secuencias unicas logradas:\",len(seq_set),\"de:\",rows)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X: (5000, 5, 100) Y: (5000, 5, 100)\n",
            "Secuencias unicas logradas: 5000 de: 5000\n",
            "X: (5000, 30, 100) Y: (5000, 30, 100)\n",
            "Secuencias unicas logradas: 5000 de: 5000\n",
            "X: (5000, 50, 100) Y: (5000, 50, 100)\n",
            "Secuencias unicas logradas: 5000 de: 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8F9gGetIX4O",
        "colab_type": "text"
      },
      "source": [
        "### <u>Mecanismo de Atención</u>\n",
        "\n",
        "El mecanismo de atención utilizado en este caso es una implementación a mano\n",
        "de la atención de Bahdanau. Los créditos de la implementación son para [Zafarali Ahmed](http://www.zafarali.me/) un interno de [Datalogue](https://www.datalogue.io/)\n",
        "\n",
        "El artículo con los códigos fuentes para responder esta pregunta están [aquí](https://machinelearningmastery.com/encoder-decoder-attention-sequence-to-sequence-prediction-keras/)\n",
        "\n",
        "#### <u> Atención de Bahdanau </u>\n",
        "\n",
        "La atención de Bahdanau multiplica los estados ocultos del encoder ($h_i$) con ciertos pesos ($a_i$) para formar el vector de contexto ($c$).\n",
        "\n",
        "$$\n",
        "c_t = \\sum_{s}^{T} = a_{ts}h_{s}\n",
        "$$\n",
        "\n",
        "Los pesos $a$ se obtienen mediante la aplicación de una operación *Softmax*:\n",
        "\n",
        "$$\n",
        "a_{ts} = \\frac{exp(score(h_t,\\bar{h}_{s}))}{\\sum_{s'}^{S}score(h_t,\\bar{h}_{s'})}\n",
        "$$\n",
        "\n",
        "a la atención de Bahdanau:\n",
        "\n",
        "$$\n",
        "score(h_t,\\bar{h}_{s}) = v^{T}tanh\\left(W_{1}h_t+W_{2}\\bar{h}_{s} \\right)\n",
        "$$\n",
        "\n",
        "Los pesos compartidos $W_i$ Los aprende una pequeña red neuronal, que estará entre Encoder y Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu0bYyvtzhFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras import regularizers, constraints, initializers, activations\n",
        "from keras.layers.recurrent import Recurrent\n",
        "from keras.engine import InputSpec\n",
        "\n",
        "#Esto debe redefinirse porque era una función antigua de keras que ya no está\n",
        "def _time_distributed_dense(x, w, b=None, dropout=None, \n",
        "                        input_dim=None, output_dim=None,\n",
        "                        timesteps=None, training=None):\n",
        "    \"\"\"Apply `y . w + b` for every temporal slice y of x.\n",
        "    # Arguments\n",
        "        x: input tensor.\n",
        "        w: weight matrix.\n",
        "        b: optional bias vector.\n",
        "        dropout: wether to apply dropout (same dropout mask\n",
        "            for every temporal slice of the input).\n",
        "        input_dim: integer; optional dimensionality of the input.\n",
        "        output_dim: integer; optional dimensionality of the output.\n",
        "        timesteps: integer; optional number of timesteps.\n",
        "        training: training phase tensor or boolean.\n",
        "    # Returns\n",
        "        Output tensor.\n",
        "    \"\"\"\n",
        "    if not input_dim:\n",
        "        input_dim = K.shape(x)[2]\n",
        "    if not timesteps:\n",
        "        timesteps = K.shape(x)[1]\n",
        "    if not output_dim:\n",
        "        output_dim = K.shape(w)[1]\n",
        "\n",
        "    if dropout is not None and 0. < dropout < 1.:\n",
        "        # apply the same dropout pattern at every timestep\n",
        "        ones = K.ones_like(K.reshape(x[:, 0, :], (-1, input_dim)))\n",
        "        dropout_matrix = K.dropout(ones, dropout)\n",
        "        expanded_dropout_matrix = K.repeat(dropout_matrix, timesteps)\n",
        "        x = K.in_train_phase(x * expanded_dropout_matrix, x, training=training)\n",
        "\n",
        "    # collapse time dimension and batch dimension together\n",
        "    x = K.reshape(x, (-1, input_dim))\n",
        "    x = K.dot(x, w)\n",
        "    if b is not None:\n",
        "        x = K.bias_add(x, b)\n",
        "    # reshape to 3D tensor\n",
        "    if K.backend() == 'tensorflow':\n",
        "        x = K.reshape(x, K.stack([-1, timesteps, output_dim]))\n",
        "        x.set_shape([None, None, output_dim])\n",
        "    else:\n",
        "        x = K.reshape(x, (-1, timesteps, output_dim))\n",
        "    return x\n",
        "\n",
        "tfPrint = lambda d, T: tf.Print(input_=T, data=[T, tf.shape(T)], message=d)\n",
        "\n",
        "class AttentionDecoder(Recurrent):\n",
        "\n",
        "    def __init__(self, units, output_dim,\n",
        "                 activation='tanh',\n",
        "                 return_probabilities=False,\n",
        "                 name='AttentionDecoder',\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 recurrent_initializer='orthogonal',\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 activity_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 **kwargs):\n",
        "        \"\"\"\n",
        "        Implements an AttentionDecoder that takes in a sequence encoded by an\n",
        "        encoder and outputs the decoded states\n",
        "        :param units: dimension of the hidden state and the attention matrices\n",
        "        :param output_dim: the number of labels in the output space\n",
        "\n",
        "        references:\n",
        "            Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio.\n",
        "            \"Neural machine translation by jointly learning to align and translate.\"\n",
        "            arXiv preprint arXiv:1409.0473 (2014).\n",
        "        \"\"\"\n",
        "        self.units = units\n",
        "        self.output_dim = output_dim\n",
        "        self.return_probabilities = return_probabilities\n",
        "        self.activation = activations.get(activation)\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.recurrent_initializer = initializers.get(recurrent_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.recurrent_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "\n",
        "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self.recurrent_constraint = constraints.get(kernel_constraint)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "\n",
        "        super(AttentionDecoder, self).__init__(**kwargs)\n",
        "        self.name = name\n",
        "        self.return_sequences = True  # must return sequences\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"\n",
        "          See Appendix 2 of Bahdanau 2014, arXiv:1409.0473\n",
        "          for model details that correspond to the matrices here.\n",
        "        \"\"\"\n",
        "\n",
        "        self.batch_size, self.timesteps, self.input_dim = input_shape\n",
        "\n",
        "        if self.stateful:\n",
        "            super(AttentionDecoder, self).reset_states()\n",
        "\n",
        "        self.states = [None, None]  # y, s\n",
        "\n",
        "        \"\"\"\n",
        "            Matrices for creating the context vector\n",
        "        \"\"\"\n",
        "\n",
        "        self.V_a = self.add_weight(shape=(self.units,),\n",
        "                                   name='V_a',\n",
        "                                   initializer=self.kernel_initializer,\n",
        "                                   regularizer=self.kernel_regularizer,\n",
        "                                   constraint=self.kernel_constraint)\n",
        "        self.W_a = self.add_weight(shape=(self.units, self.units),\n",
        "                                   name='W_a',\n",
        "                                   initializer=self.kernel_initializer,\n",
        "                                   regularizer=self.kernel_regularizer,\n",
        "                                   constraint=self.kernel_constraint)\n",
        "        self.U_a = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='U_a',\n",
        "                                   initializer=self.kernel_initializer,\n",
        "                                   regularizer=self.kernel_regularizer,\n",
        "                                   constraint=self.kernel_constraint)\n",
        "        self.b_a = self.add_weight(shape=(self.units,),\n",
        "                                   name='b_a',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "        \"\"\"\n",
        "            Matrices for the r (reset) gate\n",
        "        \"\"\"\n",
        "        self.C_r = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='C_r',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.U_r = self.add_weight(shape=(self.units, self.units),\n",
        "                                   name='U_r',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.W_r = self.add_weight(shape=(self.output_dim, self.units),\n",
        "                                   name='W_r',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.b_r = self.add_weight(shape=(self.units, ),\n",
        "                                   name='b_r',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "\n",
        "        \"\"\"\n",
        "            Matrices for the z (update) gate\n",
        "        \"\"\"\n",
        "        self.C_z = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='C_z',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.U_z = self.add_weight(shape=(self.units, self.units),\n",
        "                                   name='U_z',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.W_z = self.add_weight(shape=(self.output_dim, self.units),\n",
        "                                   name='W_z',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.b_z = self.add_weight(shape=(self.units, ),\n",
        "                                   name='b_z',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "        \"\"\"\n",
        "            Matrices for the proposal\n",
        "        \"\"\"\n",
        "        self.C_p = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='C_p',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.U_p = self.add_weight(shape=(self.units, self.units),\n",
        "                                   name='U_p',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.W_p = self.add_weight(shape=(self.output_dim, self.units),\n",
        "                                   name='W_p',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.b_p = self.add_weight(shape=(self.units, ),\n",
        "                                   name='b_p',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "        \"\"\"\n",
        "            Matrices for making the final prediction vector\n",
        "        \"\"\"\n",
        "        self.C_o = self.add_weight(shape=(self.input_dim, self.output_dim),\n",
        "                                   name='C_o',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.U_o = self.add_weight(shape=(self.units, self.output_dim),\n",
        "                                   name='U_o',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.W_o = self.add_weight(shape=(self.output_dim, self.output_dim),\n",
        "                                   name='W_o',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.b_o = self.add_weight(shape=(self.output_dim, ),\n",
        "                                   name='b_o',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "\n",
        "        # For creating the initial state:\n",
        "        self.W_s = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='W_s',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "\n",
        "        self.input_spec = [\n",
        "            InputSpec(shape=(self.batch_size, self.timesteps, self.input_dim))]\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, x):\n",
        "        # store the whole sequence so we can \"attend\" to it at each timestep\n",
        "        self.x_seq = x\n",
        "\n",
        "        # apply the a dense layer over the time dimension of the sequence\n",
        "        # do it here because it doesn't depend on any previous steps\n",
        "        # thefore we can save computation time:\n",
        "        self._uxpb = _time_distributed_dense(self.x_seq, self.U_a, b=self.b_a,\n",
        "                                             input_dim=self.input_dim,\n",
        "                                             timesteps=self.timesteps,\n",
        "                                             output_dim=self.units)\n",
        "\n",
        "        return super(AttentionDecoder, self).call(x)\n",
        "\n",
        "    def get_initial_state(self, inputs):\n",
        "        # apply the matrix on the first time step to get the initial s0.\n",
        "        s0 = activations.tanh(K.dot(inputs[:, 0], self.W_s))\n",
        "\n",
        "        # from keras.layers.recurrent to initialize a vector of (batchsize,\n",
        "        # output_dim)\n",
        "        y0 = K.zeros_like(inputs)  # (samples, timesteps, input_dims)\n",
        "        y0 = K.sum(y0, axis=(1, 2))  # (samples, )\n",
        "        y0 = K.expand_dims(y0)  # (samples, 1)\n",
        "        y0 = K.tile(y0, [1, self.output_dim])\n",
        "\n",
        "        return [y0, s0]\n",
        "\n",
        "    def step(self, x, states):\n",
        "\n",
        "        ytm, stm = states\n",
        "\n",
        "        # repeat the hidden state to the length of the sequence\n",
        "        _stm = K.repeat(stm, self.timesteps)\n",
        "\n",
        "        # now multiplty the weight matrix with the repeated hidden state\n",
        "        _Wxstm = K.dot(_stm, self.W_a)\n",
        "\n",
        "        # calculate the attention probabilities\n",
        "        # this relates how much other timesteps contributed to this one.\n",
        "        et = K.dot(activations.tanh(_Wxstm + self._uxpb),\n",
        "                   K.expand_dims(self.V_a))\n",
        "        at = K.exp(et)\n",
        "        at_sum = K.sum(at, axis=1)\n",
        "        at_sum_repeated = K.repeat(at_sum, self.timesteps)\n",
        "        at /= at_sum_repeated  # vector of size (batchsize, timesteps, 1)\n",
        "\n",
        "        # calculate the context vector\n",
        "        context = K.squeeze(K.batch_dot(at, self.x_seq, axes=1), axis=1)\n",
        "        # ~~~> calculate new hidden state\n",
        "        # first calculate the \"r\" gate:\n",
        "\n",
        "        rt = activations.sigmoid(\n",
        "            K.dot(ytm, self.W_r)\n",
        "            + K.dot(stm, self.U_r)\n",
        "            + K.dot(context, self.C_r)\n",
        "            + self.b_r)\n",
        "\n",
        "        # now calculate the \"z\" gate\n",
        "        zt = activations.sigmoid(\n",
        "            K.dot(ytm, self.W_z)\n",
        "            + K.dot(stm, self.U_z)\n",
        "            + K.dot(context, self.C_z)\n",
        "            + self.b_z)\n",
        "\n",
        "        # calculate the proposal hidden state:\n",
        "        s_tp = activations.tanh(\n",
        "            K.dot(ytm, self.W_p)\n",
        "            + K.dot((rt * stm), self.U_p)\n",
        "            + K.dot(context, self.C_p)\n",
        "            + self.b_p)\n",
        "\n",
        "        # new hidden state:\n",
        "        st = (1-zt)*stm + zt * s_tp\n",
        "\n",
        "        yt = activations.softmax(\n",
        "            K.dot(ytm, self.W_o)\n",
        "            + K.dot(stm, self.U_o)\n",
        "            + K.dot(context, self.C_o)\n",
        "            + self.b_o)\n",
        "\n",
        "        if self.return_probabilities:\n",
        "            return at, [yt, st]\n",
        "        else:\n",
        "            return yt, [yt, st]\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\"\n",
        "            For Keras internal compatability checking\n",
        "        \"\"\"\n",
        "        if self.return_probabilities:\n",
        "            return (None, self.timesteps, self.timesteps)\n",
        "        else:\n",
        "            return (None, self.timesteps, self.output_dim)\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "            For rebuilding models on load time.\n",
        "        \"\"\"\n",
        "        config = {\n",
        "            'output_dim': self.output_dim,\n",
        "            'units': self.units,\n",
        "            'return_probabilities': self.return_probabilities\n",
        "        }\n",
        "        base_config = super(AttentionDecoder, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dnn3hAVyTxe3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e90c2171-a022-4441-d927-19c799d2c05b"
      },
      "source": [
        "x_train,y_train,x_test,y_test = split_dataset(X_dataset5,Y_dataset5,rows,0.3)\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3500, 5, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i43AjaCAKnpb",
        "colab_type": "text"
      },
      "source": [
        "### Cadenas de Largo 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33401YzNu7_Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fce9c495-d72a-44e4-a3a8-ab109bcaf681"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import GRU\n",
        "from keras.layers import Dense\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import RepeatVector\n",
        "\n",
        "#Pruebas cadenas de largo 5\n",
        "x_train,y_train,x_test,y_test = split_dataset(X_dataset5,Y_dataset5,rows,0.3)\n",
        "\n",
        "model_5 = Sequential()\n",
        "model_5.add(GRU(units=150,input_shape=(5,n_unique)))\n",
        "model_5.add(RepeatVector(5))\n",
        "model_5.add(GRU(units=150,return_sequences=True))\n",
        "model_5.add(TimeDistributed(Dense(n_unique,activation=\"softmax\")))\n",
        "model_5.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "#Train\n",
        "model_5.fit(x_train,y_train,batch_size=32,epochs=20,verbose=1)\n",
        "\n",
        "#Una vez termina el entrenamiento, se hacen las predicciones\n",
        "total = x_test.shape[0]\n",
        "correctos = 0\n",
        "y_pred = model_5.predict(x_test,verbose=0)\n",
        "\n",
        "for t in range(total):\n",
        "    real = oh_decode(y_test[t])\n",
        "    pred = oh_decode(y_pred[t])\n",
        "    if real == pred:\n",
        "        correctos += 1\n",
        "print(\" \")\n",
        "print('\\033[1m' + \"Precision S.A Inversor Largo 5: \", correctos/total, '\\033[0m')\n",
        "print(\" \")\n",
        "\n",
        "model_5 = Sequential()\n",
        "model_5.add(GRU(units=150,input_shape=(5,n_unique),return_sequences=True))\n",
        "model_5.add(AttentionDecoder(150,n_unique))\n",
        "model_5.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "#Train\n",
        "model_5.fit(x_train,y_train,batch_size=32,epochs=5,verbose=1)\n",
        "\n",
        "#Una vez termina el entrenamiento, se hacen las predicciones\n",
        "total = x_test.shape[0]\n",
        "correctos = 0\n",
        "y_pred = model_5.predict(x_test,verbose=0)\n",
        "\n",
        "for t in range(total):\n",
        "    real = oh_decode(y_test[t])\n",
        "    pred = oh_decode(y_pred[t])\n",
        "    if real == pred:\n",
        "        correctos += 1\n",
        "print(\" \")\n",
        "print('\\033[1m' + \"Precision C.A Inversor Largo 5: \", correctos/total,'\\033[0m')\n",
        "print(\" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "3500/3500 [==============================] - 3s 990us/step - loss: 4.3447 - accuracy: 0.1123\n",
            "Epoch 2/20\n",
            "3500/3500 [==============================] - 3s 802us/step - loss: 3.2218 - accuracy: 0.1679\n",
            "Epoch 3/20\n",
            "3500/3500 [==============================] - 3s 810us/step - loss: 2.7050 - accuracy: 0.2128\n",
            "Epoch 4/20\n",
            "3500/3500 [==============================] - 3s 787us/step - loss: 2.4192 - accuracy: 0.2550\n",
            "Epoch 5/20\n",
            "3500/3500 [==============================] - 3s 807us/step - loss: 2.1887 - accuracy: 0.3086\n",
            "Epoch 6/20\n",
            "3500/3500 [==============================] - 3s 785us/step - loss: 1.9774 - accuracy: 0.3675\n",
            "Epoch 7/20\n",
            "3500/3500 [==============================] - 3s 789us/step - loss: 1.7798 - accuracy: 0.4278\n",
            "Epoch 8/20\n",
            "3500/3500 [==============================] - 3s 798us/step - loss: 1.6027 - accuracy: 0.4826\n",
            "Epoch 9/20\n",
            "3500/3500 [==============================] - 3s 824us/step - loss: 1.4291 - accuracy: 0.5417\n",
            "Epoch 10/20\n",
            "3500/3500 [==============================] - 3s 832us/step - loss: 1.2741 - accuracy: 0.5874\n",
            "Epoch 11/20\n",
            "3500/3500 [==============================] - 3s 795us/step - loss: 1.1255 - accuracy: 0.6375\n",
            "Epoch 12/20\n",
            "3500/3500 [==============================] - 3s 846us/step - loss: 0.9922 - accuracy: 0.6882\n",
            "Epoch 13/20\n",
            "3500/3500 [==============================] - 3s 841us/step - loss: 0.8693 - accuracy: 0.7315\n",
            "Epoch 14/20\n",
            "3500/3500 [==============================] - 3s 854us/step - loss: 0.7623 - accuracy: 0.7719\n",
            "Epoch 15/20\n",
            "3500/3500 [==============================] - 3s 839us/step - loss: 0.6652 - accuracy: 0.8092\n",
            "Epoch 16/20\n",
            "3500/3500 [==============================] - 3s 810us/step - loss: 0.5775 - accuracy: 0.8467\n",
            "Epoch 17/20\n",
            "3500/3500 [==============================] - 3s 834us/step - loss: 0.4986 - accuracy: 0.8774\n",
            "Epoch 18/20\n",
            "3500/3500 [==============================] - 3s 844us/step - loss: 0.4357 - accuracy: 0.8990\n",
            "Epoch 19/20\n",
            "3500/3500 [==============================] - 3s 803us/step - loss: 0.3742 - accuracy: 0.9235\n",
            "Epoch 20/20\n",
            "3500/3500 [==============================] - 3s 808us/step - loss: 0.3166 - accuracy: 0.9438\n",
            " \n",
            "\u001b[1mPrecision S.A Inversor Largo 5:  0.046 \u001b[0m\n",
            " \n",
            "Epoch 1/5\n",
            "3500/3500 [==============================] - 6s 2ms/step - loss: 4.2873 - accuracy: 0.1546\n",
            "Epoch 2/5\n",
            "3500/3500 [==============================] - 5s 1ms/step - loss: 2.6988 - accuracy: 0.2835\n",
            "Epoch 3/5\n",
            "3500/3500 [==============================] - 5s 1ms/step - loss: 1.2885 - accuracy: 0.7460\n",
            "Epoch 4/5\n",
            "3500/3500 [==============================] - 5s 1ms/step - loss: 0.4613 - accuracy: 0.9858\n",
            "Epoch 5/5\n",
            "3500/3500 [==============================] - 5s 1ms/step - loss: 0.1810 - accuracy: 0.9999\n",
            " \n",
            "\u001b[1mPrecision W.A Inversor Largo 5:  0.9993333333333333 \u001b[0m\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnyfu2f8KqtY",
        "colab_type": "text"
      },
      "source": [
        "### Cadenas de Largo 30 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THNvZosqJ-nr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6cd2d1f5-0caa-434d-d725-167805af77b9"
      },
      "source": [
        "#Pruebas cadenas de largo 30\n",
        "def contar_diferencia(true_y,pred_y):\n",
        "    total = 0\n",
        "    for y,y_hat in zip(true_y,pred_y):\n",
        "        if y != y_hat:\n",
        "            total += 1\n",
        "    return total\n",
        "\n",
        "\n",
        "x_train,y_train,x_test,y_test = split_dataset(X_dataset30,Y_dataset30,rows,0.3)\n",
        "\n",
        "model_30 = Sequential()\n",
        "model_30.add(GRU(units=150,input_shape=(30,n_unique)))\n",
        "model_30.add(RepeatVector(30))\n",
        "model_30.add(GRU(units=150,return_sequences=True))\n",
        "model_30.add(TimeDistributed(Dense(n_unique,activation=\"softmax\")))\n",
        "model_30.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "#Train\n",
        "model_30.fit(x_train,y_train,batch_size=32,epochs=20,verbose=1)\n",
        "\n",
        "#Una vez termina el entrenamiento, se hacen las predicciones\n",
        "total = x_test.shape[0]\n",
        "correctos = 0\n",
        "y_pred = model_30.predict(x_test,verbose=0)\n",
        "\n",
        "for t in range(total):\n",
        "    real = oh_decode(y_test[t])\n",
        "    pred = oh_decode(y_pred[t])\n",
        "    correctos += contar_diferencia(real,pred)\n",
        "  \n",
        "print(\" \")\n",
        "print('\\033[1m' + \"Errores promedio por secuencia S.A Largo 30: \", correctos/total, '\\033[0m')\n",
        "print(\" \")\n",
        "\n",
        "model_30 = Sequential()\n",
        "model_30.add(GRU(units=150,input_shape=(30,n_unique),return_sequences=True))\n",
        "model_30.add(AttentionDecoder(150,n_unique))\n",
        "model_30.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "#Train\n",
        "model_30.fit(x_train,y_train,batch_size=32,epochs=10,verbose=1)\n",
        "\n",
        "#Una vez termina el entrenamiento, se hacen las predicciones\n",
        "total = x_test.shape[0]\n",
        "correctos = 0\n",
        "y_pred = model_30.predict(x_test,verbose=0)\n",
        "\n",
        "for t in range(total):\n",
        "    real = oh_decode(y_test[t])\n",
        "    pred = oh_decode(y_pred[t])\n",
        "    correctos += contar_diferencia(real,pred)\n",
        "print(\" \")\n",
        "print('\\033[1m' + \"Errores promedio por secuencia C.A Largo 30: \", correctos/total, '\\033[0m')\n",
        "print(\" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "3500/3500 [==============================] - 14s 4ms/step - loss: 4.6019 - accuracy: 0.0166\n",
            "Epoch 2/20\n",
            "3500/3500 [==============================] - 14s 4ms/step - loss: 4.5382 - accuracy: 0.0224\n",
            "Epoch 3/20\n",
            "3500/3500 [==============================] - 14s 4ms/step - loss: 4.4651 - accuracy: 0.0264\n",
            "Epoch 4/20\n",
            "3500/3500 [==============================] - 14s 4ms/step - loss: 4.4092 - accuracy: 0.0292\n",
            "Epoch 5/20\n",
            "3500/3500 [==============================] - 14s 4ms/step - loss: 4.3652 - accuracy: 0.0314\n",
            "Epoch 6/20\n",
            "3500/3500 [==============================] - 14s 4ms/step - loss: 4.3202 - accuracy: 0.0334\n",
            "Epoch 7/20\n",
            "3500/3500 [==============================] - 14s 4ms/step - loss: 4.2830 - accuracy: 0.0349\n",
            "Epoch 8/20\n",
            "3500/3500 [==============================] - 13s 4ms/step - loss: 4.2439 - accuracy: 0.0381\n",
            "Epoch 9/20\n",
            "3500/3500 [==============================] - 14s 4ms/step - loss: 4.2057 - accuracy: 0.0395\n",
            "Epoch 10/20\n",
            "3500/3500 [==============================] - 14s 4ms/step - loss: 4.1717 - accuracy: 0.0423\n",
            "Epoch 11/20\n",
            "3500/3500 [==============================] - 14s 4ms/step - loss: 4.1416 - accuracy: 0.0460\n",
            "Epoch 12/20\n",
            "3500/3500 [==============================] - 14s 4ms/step - loss: 4.1117 - accuracy: 0.0486\n",
            "Epoch 13/20\n",
            "3500/3500 [==============================] - 14s 4ms/step - loss: 4.0808 - accuracy: 0.0524\n",
            "Epoch 14/20\n",
            "3500/3500 [==============================] - 14s 4ms/step - loss: 4.0521 - accuracy: 0.0548\n",
            "Epoch 15/20\n",
            "3500/3500 [==============================] - 14s 4ms/step - loss: 4.0232 - accuracy: 0.0580\n",
            "Epoch 16/20\n",
            "3500/3500 [==============================] - 14s 4ms/step - loss: 3.9971 - accuracy: 0.0609\n",
            "Epoch 17/20\n",
            "3500/3500 [==============================] - 14s 4ms/step - loss: 3.9706 - accuracy: 0.0631\n",
            "Epoch 18/20\n",
            "3500/3500 [==============================] - 14s 4ms/step - loss: 3.9446 - accuracy: 0.0666\n",
            "Epoch 19/20\n",
            "3500/3500 [==============================] - 14s 4ms/step - loss: 3.9206 - accuracy: 0.0697\n",
            "Epoch 20/20\n",
            "3500/3500 [==============================] - 14s 4ms/step - loss: 3.8955 - accuracy: 0.0729\n",
            " \n",
            "\u001b[1mPrecision S.A Inversor Largo 30:  28.461333333333332 \u001b[0m\n",
            " \n",
            "Epoch 1/10\n",
            "3500/3500 [==============================] - 25s 7ms/step - loss: 4.5365 - accuracy: 0.0235\n",
            "Epoch 2/10\n",
            "3500/3500 [==============================] - 24s 7ms/step - loss: 4.3565 - accuracy: 0.0305\n",
            "Epoch 3/10\n",
            "3500/3500 [==============================] - 24s 7ms/step - loss: 3.9764 - accuracy: 0.0765\n",
            "Epoch 4/10\n",
            "3500/3500 [==============================] - 24s 7ms/step - loss: 2.9463 - accuracy: 0.2245\n",
            "Epoch 5/10\n",
            "3500/3500 [==============================] - 24s 7ms/step - loss: 2.3151 - accuracy: 0.3436\n",
            "Epoch 6/10\n",
            "3500/3500 [==============================] - 23s 7ms/step - loss: 1.5443 - accuracy: 0.5345\n",
            "Epoch 7/10\n",
            "3500/3500 [==============================] - 23s 7ms/step - loss: 0.9092 - accuracy: 0.7388\n",
            "Epoch 8/10\n",
            "3500/3500 [==============================] - 23s 7ms/step - loss: 2.5829 - accuracy: 0.3559\n",
            "Epoch 9/10\n",
            "3500/3500 [==============================] - 23s 7ms/step - loss: 0.8692 - accuracy: 0.7314\n",
            "Epoch 10/10\n",
            "3500/3500 [==============================] - 24s 7ms/step - loss: 0.6583 - accuracy: 0.8042\n",
            " \n",
            "\u001b[1mPrecision W.A Inversor Largo 30:  6.898 \u001b[0m\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y-MvQ2DW0M5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "280de815-dd68-485e-d42b-9a0b66658d2a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_indexes(unique):\n",
        "    indexes = {}\n",
        "    for i in range(unique):\n",
        "        indexes[i] = 0\n",
        "    return indexes\n",
        "\n",
        "def update_indexes(indexes,true_y,pred_y):\n",
        "    index = 0\n",
        "    for y,y_hat in zip(true_y,pred_y):\n",
        "        if y != y_hat:\n",
        "            indexes[index] += 1\n",
        "        index +=1\n",
        "    return indexes\n",
        "\n",
        "\n",
        "diccio = generate_indexes(30)\n",
        "for t in range(total):\n",
        "    real = oh_decode(y_test[t])\n",
        "    pred = oh_decode(y_pred[t])\n",
        "    diccio = update_indexes(diccio,real,pred)\n",
        "\n",
        "plt.bar(x=diccio.keys(),height=diccio.values())\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Errores en index\")\n",
        "plt.title(\"Total errores: \"+str(sum(diccio.values())))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJv6tFa5KvcA",
        "colab_type": "text"
      },
      "source": [
        "### Cadenas de Largo 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIELAyJTKNn9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a0d18ded-3116-42f2-c64f-34f19d33fe8a"
      },
      "source": [
        "#Pruebas cadenas de largo 50\n",
        "x_train,y_train,x_test,y_test = split_dataset(X_dataset50,Y_dataset50,rows,0.3)\n",
        "\n",
        "model_50 = Sequential()\n",
        "model_50.add(GRU(units=150,input_shape=(50,n_unique)))\n",
        "model_50.add(RepeatVector(50))\n",
        "model_50.add(GRU(units=150,return_sequences=True))\n",
        "model_50.add(TimeDistributed(Dense(n_unique,activation=\"softmax\")))\n",
        "model_50.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "#Train\n",
        "model_50.fit(x_train,y_train,batch_size=32,epochs=20,verbose=1)\n",
        "\n",
        "#Una vez termina el entrenamiento, se hacen las predicciones\n",
        "total = x_test.shape[0]\n",
        "correctos = 0\n",
        "y_pred = model_50.predict(x_test,verbose=0)\n",
        "\n",
        "for t in range(total):\n",
        "    real = oh_decode(y_test[t])\n",
        "    pred = oh_decode(y_pred[t])\n",
        "    correctos += contar_diferencia(real,pred)\n",
        "    \n",
        "print(\" \")\n",
        "print('\\033[1m' + \"Errores promedio por secuencia S.A Largo 50: \", correctos/total, '\\033[0m')\n",
        "print(\" \")\n",
        "\n",
        "\n",
        "model_50 = Sequential()\n",
        "model_50.add(GRU(units=150,input_shape=(50,n_unique),return_sequences=True))\n",
        "model_50.add(AttentionDecoder(150,n_unique))\n",
        "model_50.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "#Train\n",
        "model_50.fit(x_train,y_train,batch_size=32,epochs=10,verbose=1)\n",
        "\n",
        "#Una vez termina el entrenamiento, se hacen las predicciones\n",
        "total = x_test.shape[0]\n",
        "correctos = 0\n",
        "y_pred = model_50.predict(x_test,verbose=0)\n",
        "\n",
        "for t in range(total):\n",
        "    real = oh_decode(y_test[t])\n",
        "    pred = oh_decode(y_pred[t])\n",
        "    correctos += contar_diferencia(real,pred)\n",
        "    \n",
        "print(\" \")\n",
        "print('\\033[1m' + \"Errores promedio por secuencia C.A Largo 50: \", correctos/total, '\\033[0m')\n",
        "print(\" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "3500/3500 [==============================] - 23s 6ms/step - loss: 4.6052 - accuracy: 0.0111\n",
            "Epoch 2/20\n",
            "3500/3500 [==============================] - 22s 6ms/step - loss: 4.5965 - accuracy: 0.0160\n",
            "Epoch 3/20\n",
            "3500/3500 [==============================] - 22s 6ms/step - loss: 4.5708 - accuracy: 0.0171\n",
            "Epoch 4/20\n",
            "3500/3500 [==============================] - 22s 6ms/step - loss: 4.5504 - accuracy: 0.0192\n",
            "Epoch 5/20\n",
            "3500/3500 [==============================] - 21s 6ms/step - loss: 4.5311 - accuracy: 0.0213\n",
            "Epoch 6/20\n",
            "3500/3500 [==============================] - 22s 6ms/step - loss: 4.5118 - accuracy: 0.0234\n",
            "Epoch 7/20\n",
            "3500/3500 [==============================] - 22s 6ms/step - loss: 4.4928 - accuracy: 0.0258\n",
            "Epoch 8/20\n",
            "3500/3500 [==============================] - 22s 6ms/step - loss: 4.4736 - accuracy: 0.0277\n",
            "Epoch 9/20\n",
            "3500/3500 [==============================] - 22s 6ms/step - loss: 4.4528 - accuracy: 0.0306\n",
            "Epoch 10/20\n",
            "3500/3500 [==============================] - 23s 6ms/step - loss: 4.4335 - accuracy: 0.0325\n",
            "Epoch 11/20\n",
            "3500/3500 [==============================] - 22s 6ms/step - loss: 4.4151 - accuracy: 0.0343\n",
            "Epoch 12/20\n",
            "3500/3500 [==============================] - 22s 6ms/step - loss: 4.3981 - accuracy: 0.0365\n",
            "Epoch 13/20\n",
            "3500/3500 [==============================] - 22s 6ms/step - loss: 4.3824 - accuracy: 0.0381\n",
            "Epoch 14/20\n",
            "3500/3500 [==============================] - 22s 6ms/step - loss: 4.3668 - accuracy: 0.0395\n",
            "Epoch 15/20\n",
            "3500/3500 [==============================] - 22s 6ms/step - loss: 4.3525 - accuracy: 0.0412\n",
            "Epoch 16/20\n",
            "3500/3500 [==============================] - 22s 6ms/step - loss: 4.3388 - accuracy: 0.0427\n",
            "Epoch 17/20\n",
            "3500/3500 [==============================] - 22s 6ms/step - loss: 4.3233 - accuracy: 0.0445\n",
            "Epoch 18/20\n",
            "3500/3500 [==============================] - 22s 6ms/step - loss: 4.3094 - accuracy: 0.0463\n",
            "Epoch 19/20\n",
            "3500/3500 [==============================] - 23s 6ms/step - loss: 4.2953 - accuracy: 0.0481\n",
            "Epoch 20/20\n",
            "3500/3500 [==============================] - 22s 6ms/step - loss: 4.2824 - accuracy: 0.0495\n",
            " \n",
            "\u001b[1mErrores promedio por secuencia S.A Largo 50:  48.09466666666667 \u001b[0m\n",
            " \n",
            "Epoch 1/10\n",
            "3500/3500 [==============================] - 40s 12ms/step - loss: 4.5808 - accuracy: 0.0160\n",
            "Epoch 2/10\n",
            "3500/3500 [==============================] - 38s 11ms/step - loss: 4.5071 - accuracy: 0.0188\n",
            "Epoch 3/10\n",
            "3500/3500 [==============================] - 39s 11ms/step - loss: 4.4551 - accuracy: 0.0205\n",
            "Epoch 4/10\n",
            "3500/3500 [==============================] - 37s 11ms/step - loss: 4.2356 - accuracy: 0.0504\n",
            "Epoch 5/10\n",
            "3500/3500 [==============================] - 37s 11ms/step - loss: 3.2182 - accuracy: 0.1790\n",
            "Epoch 6/10\n",
            "3500/3500 [==============================] - 38s 11ms/step - loss: 2.3876 - accuracy: 0.3002\n",
            "Epoch 7/10\n",
            "3500/3500 [==============================] - 37s 11ms/step - loss: 1.8652 - accuracy: 0.4111\n",
            "Epoch 8/10\n",
            "3500/3500 [==============================] - 37s 10ms/step - loss: 1.7743 - accuracy: 0.4503\n",
            "Epoch 9/10\n",
            "3500/3500 [==============================] - 36s 10ms/step - loss: 1.1966 - accuracy: 0.5970\n",
            "Epoch 10/10\n",
            "3500/3500 [==============================] - 37s 10ms/step - loss: 0.9930 - accuracy: 0.6536\n",
            " \n",
            "\u001b[1mErrores promedio por secuencia C.A Largo 50:  13.586 \u001b[0m\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk6krYLPbFl1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b04168f6-9432-42c4-ea8a-5ecd8fc7b6f3"
      },
      "source": [
        "diccio = generate_indexes(50)\n",
        "for t in range(total):\n",
        "    real = oh_decode(y_test[t])\n",
        "    pred = oh_decode(y_pred[t])\n",
        "    diccio = update_indexes(diccio,real,pred)\n",
        "\n",
        "plt.bar(x=diccio.keys(),height=diccio.values())\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Errores en index\")\n",
        "plt.title(\"Total errores: \"+str(sum(diccio.values())))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAcQUlEQVR4nO3de7QU5Znv8e9P8BZvCOywuIpGxhwzUfAwiqMrY2R5gTjijMbRGCWGhMw5JqMnMUqcrJnRxBlda+JtTEiIJqIxKpp4IGomEtRJYo4Y8II3XBKUACKgUQQZNcpz/qi3y3KzYdeGXd17d/8+a/XqqrfeqnoKevfT7/vWRRGBmZkZwA6NDsDMzHoOJwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4I1FUkhaf9Gx2HWWzkpWF1I2lB4bZL034X5M7awzlGSVtQ71p5O0jhJcyX9UdJaSbdLGlxYLkmXS3olvS6XpLRsoKQHU/lrkv6fpCMK63633f/VW5LWF5b/D0n3SVonaYmkv6nv0VvVnBSsLiJi99oL+APw14WymxsdX3uS+nZQ1qeL2+hS/S7YG5gBjAT2AdYDPywsnwqcBBwMHAT8NfCFtGwD8FmgLW3ncuBnteONiL9v9391C3B7Op6+wGzgLqB/2s+PJP1ZRcdpDeCkYA0laWdJV0l6Mb2uSmW7AT8HhhR+tQ6RdGj6dfuapFWSrpW0U8l97SXp+rTeSknfrH1xS/pM+gV9paRXgH+RdIOk6ZLukfQG8PH0S/mBtP+nJJ1Y2H5H9YdI+kn6Rf+8pH8o1D9U0gJJr0taLemKMscRET+PiNsj4vWI2AhcCxxRqDIZ+FZErIiIlcC3gM+kdd+MiGcjYhMg4F2y5NC/g3+v3YCTgZmp6MPAEODKiHg3Iu4DHgTOLBO39Q5OCtZo/wiMA0aT/bI9FPh6RLwBTABeLPxyfZHsS+z/AAOBw4HxwP8uua8bgHeA/YExwLHA5wrLDwOWAoOAS1PZp9L0HsB84GfAvcAHgS8BN0s6oLCNYv3fpvqPA0NTrOdJOi7VvRq4OiL2BD4EzKptRNIiSZ8qeVwfA54qzH8k7bPm8VSWk7QIeBOYA1wXEWs62O7JwFrgV1vZt4A/Lxmn9QJOCtZoZwCXRMSaiFgLXMxWfnlGxMKIeCgi3omIF4DvAX/V2U4kDQImAudFxBvpS/BK4LRCtRcj4j/Stv87lc2OiAfTL+vRwO7AZRHxdvqlfBdwemEbxfofBdoi4pJUfynw/cI+/wTsL2lgRGyIiIcKx3lQRPy4xHEdBPwT8NVC8e7AusL8OmD32rhCbfvAnmRJ7Ddb2Pxk4MZ47wZpzwJrgK9K2lHSsWT/9h/oLE7rPTbrNzWrsyHAssL8slTWodR/fQUwluzLqC+wsMR+9gF2BFYVvht3AJYX6ixvv1K7siHA8vSFX4x36Bbq70PW/fVaoawP8Os0PQW4BFgs6Xng4oi4q8SxAJDOsvo5cG5E/LqwaAPZF37NnsCGwpc7kHUlAbdIekbSYxGRty4kjQCOAj5fqP8nSScB/wFcCCwga928VTZm6/ncUrBGe5Hsy7NmRCoD6OgWvtOBxcCo1O1yEVkXRmeWk315DYyIfum1Z0QUu1U62l+x7EVguKTi380IYOUW6i8Hni/sr19E7BEREwEi4rmIOJ2sK+py4I7Uj98pSfsAvwS+ERE3tVv8FFlXXM3BvL97qb0dgf3alZ0JPJhaN+8dXMSiiPiriBgQEcel9R4uE7P1Dk4K1mi3AF+X1CZpIFlXyI/SstXAAEl7FervAbwObJD0YeB/ldlJRKwiGwv4lqQ9Je0g6UOSOu16KpgPbAQuSN0nR5Gd2XPrFuo/DKyXdKGkXSX1kfTnkv4CQNKnJbWllketNbFpC9vKSRoK3AdcGxHf7aDKjcCXJQ2VNAT4Ctl4Su101iMl7ZRiupBsDGV+u22cVVun3b4PkrSLpA9IOh8Y3FE9672cFKzRvknWDbEIeAJ4JJUREYvJksbSdLbPEOB8sn7w9WT987d1YV9nATsBTwOvAneQfamVEhFvkyWBCcDLwHeAs1KcHdV/FziBbCzi+bTOdUAtyR0PPCVpA9mg82m1sYx0ZlOH12+QDY7vR3aGVH5NQWH598gGuJ8AngTuTmUAOwPfBl4ha+FMBD6RBvFJ+z4cGEY6FbWdM4FVZGML44FjIsLdR01EfsiOmZnVuKVgZmY5JwUzM8s5KZiZWc5JwczMcr364rWBAwfGyJEjGx2GmVmvsnDhwpcjoq2jZb06KYwcOZIFCxY0Ogwzs15F0rItLXP3kZmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeV69RXNZma90chpd79v/oXLPtGgSDbnloKZmeWcFMzMLOekYGZmOScFMzPLeaDZzKyHaD8ADfUfhHZLwczMcpUlBUkHSHqs8Hpd0nmS+kuaK+m59L53qi9J10haImmRpEOqis3MzDpWWVKIiGcjYnREjAb+J7ARuBOYBsyLiFHAvDQPMAEYlV5TgelVxWZmZh2rV/fReOD3EbEMmATMTOUzgZPS9CTgxsg8BPSTNLhO8ZmZGfVLCqcBt6TpQRGxKk2/BAxK00OB5YV1VqSy95E0VdICSQvWrl1bVbxmZi2p8qQgaSfgROD29ssiIoDoyvYiYkZEjI2IsW1tbd0UpZmZQX1aChOARyJidZpfXesWSu9rUvlKYHhhvWGpzMzM6qQeSeF03us6ApgDTE7Tk4HZhfKz0llI44B1hW4mMzOrg0ovXpO0G3AM8IVC8WXALElTgGXAqan8HmAisITsTKWzq4zNzMw2V2lSiIg3gAHtyl4hOxupfd0AzqkyHjMz2zpf0WxmZjnf+8jMrAI94T5G28ItBTMzyzkpmJlZzknBzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOT9kx3qV3vrgErPeotKWgqR+ku6QtFjSM5IOl9Rf0lxJz6X3vVNdSbpG0hJJiyQdUmVsZma2uapbClcD/xkRp0jaCfgAcBEwLyIukzQNmAZcCEwARqXXYcD09G5m1mM1W+u1spaCpL2AjwHXA0TE2xHxGjAJmJmqzQROStOTgBsj8xDQT9LgquIzM7PNVdl9tC+wFvihpEclXSdpN2BQRKxKdV4CBqXpocDywvorUtn7SJoqaYGkBWvXrq0wfDOz1lNlUugLHAJMj4gxwBtkXUW5iAggurLRiJgREWMjYmxbW1u3BWtmZtUmhRXAioiYn+bvIEsSq2vdQul9TVq+EhheWH9YKjMzszqpLClExEvAckkHpKLxwNPAHGByKpsMzE7Tc4Cz0llI44B1hW4mMzOrg6rPPvoScHM682gpcDZZIpolaQqwDDg11b0HmAgsATamutaimu2MDuv9WuUzWWlSiIjHgLEdLBrfQd0AzqkyHjMz2zrf5sLMzHJOCmZmlnNSMDOznJOCmZnlnBTMzCznpGBmZjknBTMzy/khO2bttMpFSmYdcUvBzMxyTgpmZpZzUjAzs5zHFKyhuqv/3uMAZt3DLQUzM8s5KZiZWc5JwczMcp2OKUjaJSLebFc2MCJeri4ss+7TfrzBYw1mW1ampfC79HhMACSdDPy2upDMzKxRypx99CngB5IeAIYAA4CjqwzKzMwao9OkEBFPSLoUuAlYD3wsIlZUHpmZmdVdp91Hkq4HzgMOAs4G7pJU6lnKkl6Q9ISkxyQtSGX9Jc2V9Fx63zuVS9I1kpZIWiTpkG0/LDMz2xZluo+eAD4XEQE8L+kw4Iou7OPj7QalpwHzIuIySdPS/IXABGBUeh0GTE/vZj2CL5CzVlCm++gqSftIGhURvwTeJms5bKtJwFFpeibwAFlSmATcmJLPQ5L6SRocEau2Y19mZl3S6sm/zCmpnwemAv2BDwHDgO8C40tsP4B7JQXwvYiYAQwqfNG/BAxK00OB5YV1V6Sy9yUFSVNTPIwYMaJECGYda/U/frOOlOk+Ogc4FJgPEBHPSfpgye0fGRErU/25khYXF0ZEpIRRWkosMwDGjh3bpXXNzGzryiSFtyLibUkASOpL1gLoVESsTO9rJN1JllxW17qFJA0G1qTqK4HhhdWHpTJrAv5VbtY7lLl47b8kXQTsKukY4HbgZ52tJGk3SXvUpoFjgSeBOcDkVG0yMDtNzwHOSmchjQPWeTzBzKy+yrQUpgFTyM5C+gJwD3BdifUGAXemFkZf4McR8Z+SfgfMkjQFWAacmurfA0wElgAbyU5/NTOzOipz9tEm4PvpVVpELAUO7qD8FToYpE5nHZW6/sHMzKqxxaQg6Qm2MnYQEQdVEpFZL+PxEmsmW2spnJDea7/eb0rvn6bkQLO1Hn9BmvVuW0wKEbEMQNIxETGmsOhCSY+QjTVYi/KXv1lzKnP2kSQdUZj5y5LrmZlZL1Pm7KMpZLfO3gsQ8Crw2UqjMmsCbk1Zb1Tm7KOFwMEpKRAR6yqPysysYk7aHStz76OdgZOBkUDf2pXNEXFJpZGZmXUDf/l3TZnuo9nAOmAh8Fa14ZiZWSOVSQrDIuL4yiMxM7OGK3MW0W8lfbTySMzMrOHKtBSOBD4j6Xmy7iOR3ZXCVzSbmTWZMklhQuVRmJlZj7C1ex/tGRGvA+vrGI/1MD5zw6zx6vl3uLWWwo/J7n+0kOxeRyosC2C/SiIyM7OG2dq9j05I7/vWLxyz5ufWl/VkvoeRmZnlnBTMzCxX5uwjM6sDdytZT1AqKUjqQ/bM5bx+RPyhqqDMzKwxOu0+kvQlYDUwF7g7ve4quwNJfSQ9KumuNL+vpPmSlki6TdJOqXznNL8kLR+5DcdjZmbbocyYwrnAARHxkYj4aHp15Wrmc4FnCvOXA1dGxP5kz2aYksqnAK+m8itTPTMzq6My3UfLye6S2mWShgGfAC4FvqzsvttHA59KVWYC/wJMByalaYA7gGslKSL8PGgz65THZLpHmaSwFHhA0t0Ubp0dEVeUWPcq4AJgjzQ/AHgtIt5J8yuAoWl6KFkCIiLekbQu1X+5uEFJU4GpACNGjCgRgpmZlVWm++gPZOMJO5F9uddeWyXpBGBNenJbt4mIGRExNiLGtrW1deemzcxaXpnHcV4MIOkDEbGxC9s+AjhR0kRgF2BP4Gqgn6S+qbUwDFiZ6q8EhgMrJPUF9gJe6cL+zMxsO5U5++hwSU8Di9P8wZK+09l6EfG1iBgWESOB04D7IuIM4H7glFRtMtmT3QDmpHnS8vs8nmBmVl9luo+uAo4j/WqPiMeBj23HPi8kG3ReQjZmcH0qvx4YkMq/DEzbjn2Ymdk2KHXxWkQsz04cyr3blZ1ExAPAA2l6KXBoB3XeBD7Zle2amVn3KnVKqqS/BELSjmx+3UHLaH/Km093M7NmU6b76O+Bc8hOGV0JjE7zZmbWZMqcffQycEYdYrEGciuo5/JFWVZPvnW2mZnlnBTMzCzn5ymYWa/i7rRqdZoUJJ0L/BBYD1wHjAGmRcS9FcdmZi3M41yNUaal8NmIuFrSccDewJnATUBTJgX/CjGzVlZmTKF21dpE4KaIeKpQZmZmTaRMUlgo6V6ypPALSXsAm6oNy8zMGqFM99EUsgvWlkbERkkDgLOrDcvMzBqhTEshgAOBf0jzu5HdCtvMzJpMmZbCd8i6i44GLiE7C+knwF9UGJdVwIPoZtaZMknhsIg4RNKjABHxqqSdKo7LzMwaoEz30Z8k9SHrRkJSGx5oNjNrSmVaCtcAdwIflHQp2VPRvl5pVGbWEtyl2fNsNSlI2gF4HrgAGE92fcJJEdGSz1Mw62l81a91t60mhYjYJOnbETGG9IxmMzNrXmW6j+ZJOhn4aURE1QHZ9nOT3My2VZmB5i8AtwNvS1qfXq93tpKkXSQ9LOlxSU9JujiV7ytpvqQlkm6rnckkaec0vyQtH7kdx2VmZtugzJPX9tjGbb8FHB0RG9KznX8j6efAl4ErI+JWSd8lu2J6enp/NSL2l3QacDnwd9u4707517SZ2eZKPWRH0omS/j29TiizTmQ2pNkd0yvILoK7I5XPBE5K05PSPGn5eEm+8Z6ZWR11mhQkXQacCzydXudK+rcyG5fUR9JjwBpgLvB74LWIeCdVWQEMTdNDgeUAafk6YEAH25wqaYGkBWvXri0ThpmZlVRmoHkiMDoiNgFImgk8CnytsxUj4l1gtKR+ZNc6fHg7Yq1tcwYwA2Ds2LEe+DbrgLtHbVuVfUZzv8L0Xl3dSUS8BtwPHA70k1RLRsOAlWl6JTAcIC3fC3ilq/syM7NtVyYp/CvwqKQbUithIXBpZytJakstBCTtChwDPEOWHE5J1SYDs9P0nDRPWn6fT4E1M6uvMlc0bwLG8d5dUS+MiJdKbHswMDPdN2kHYFZE3CXpaeBWSd8k64a6PtW/HrhJ0hLgj8BpXT4aM9sqdytZZ8pc0XxBRMwi+yVfWkQsAsZ0UL4UOLSD8jeBT3ZlH2Zm1r3KdB/9UtL5koZL6l97VR6ZmZnVXZmzj2oXkJ1TKAtgv+4Px8yakbuteo8yYwrTIuK2OsVjXeA/NDPrblvtPkrXJny1TrGYmVmDeUzBzMxyHlMwM7Ncmbuk7luPQMzMrPG22H0k6YLC9CfbLfvXKoMyM7PG2NqYQvGK4vY3vzu+gljMzKzBtpYUtIXpjubNzKwJbG1MIbYw3dG8mbUQXyPTvLaWFA5Oz2IWsGvhucwCdqk8MjMzq7stJoWI6FPPQMyscbrrl79bEL1f2YfsmJlZC3BSMDOzXJkrms2sRbk7qPW4pWBmZjknBTMzyzkpmJlZrrIxBUnDgRuBQWQXu82IiKvTbbdvA0YCLwCnRsSrkgRcDUwENgKfiYhHqoqvN3G/rpnVS5UthXeAr0TEgcA44BxJBwLTgHkRMQqYl+YBJgCj0msqML3C2MzMrAOVJYWIWFX7pR8R64FngKHAJGBmqjYTOClNTwJujMxDQD9Jg6uKz8zMNleXMQVJI4ExwHxgUESsSoteIutegixhLC+stiKVmZlZnVR+nYKk3YGfAOdFxOvZ0EEmIkJSl26uJ2kqWfcSI0aM6M5Qt5n7/M2sWVTaUpC0I1lCuDkifpqKV9e6hdL7mlS+EhheWH1YKnufiJgREWMjYmxbW1t1wZuZtaAqzz4ScD3wTERcUVg0B5gMXJbeZxfKvyjpVuAwYF2hm6kluMVhZo1WZffREcCZwBOSHktlF5Elg1mSpgDLgFPTsnvITkddQnZK6tkVxmZmZh2oLClExG/Y8hPaxndQP4BzqorHzMw65yuazcws56RgZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOScFMzPLVf48Bduc74ZqZj2VWwpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc7XKVTI1yOYWW9TWUtB0g8krZH0ZKGsv6S5kp5L73unckm6RtISSYskHVJVXGZmtmVVdh/dABzfrmwaMC8iRgHz0jzABGBUek0FplcYl5mZbUFlSSEifgX8sV3xJGBmmp4JnFQovzEyDwH9JA2uKjYzM+tYvQeaB0XEqjT9EjAoTQ8FlhfqrUhlm5E0VdICSQvWrl1bXaRmZi2oYWcfRUQAsQ3rzYiIsRExtq2trYLIzMxaV72Twupat1B6X5PKVwLDC/WGpTIzM6ujeieFOcDkND0ZmF0oPyudhTQOWFfoZjIzszqp7DoFSbcARwEDJa0A/hm4DJglaQqwDDg1Vb8HmAgsATYCZ1cVl5mZbVllSSEiTt/CovEd1A3gnKpiMTOzcnybCzMzyzkpmJlZzknBzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOScFMzPLOSmYmVnOScHMzHI9KilIOl7Ss5KWSJrW6HjMzFpNj0kKkvoA3wYmAAcCp0s6sLFRmZm1lh6TFIBDgSURsTQi3gZuBSY1OCYzs5aiiGh0DABIOgU4PiI+l+bPBA6LiC+2qzcVmJpmDwCe7YbdDwRe7obt9CY+5tbgY24NXT3mfSKiraMFfbsnnvqJiBnAjO7cpqQFETG2O7fZ0/mYW4OPuTV05zH3pO6jlcDwwvywVGZmZnXSk5LC74BRkvaVtBNwGjCnwTGZmbWUHtN9FBHvSPoi8AugD/CDiHiqTrvv1u6oXsLH3Bp8zK2h2465xww0m5lZ4/Wk7iMzM2swJwUzM8u1dFJoldtqSPqBpDWSniyU9Zc0V9Jz6X3vRsbYnSQNl3S/pKclPSXp3FTetMcMIGkXSQ9Lejwd98WpfF9J89Pn/LZ0IkfTkNRH0qOS7krzTX28AJJekPSEpMckLUhl3fL5btmk0GK31bgBOL5d2TRgXkSMAual+WbxDvCViDgQGAeck/5vm/mYAd4Cjo6Ig4HRwPGSxgGXA1dGxP7Aq8CUBsZYhXOBZwrzzX68NR+PiNGF6xO65fPdskmBFrqtRkT8Cvhju+JJwMw0PRM4qa5BVSgiVkXEI2l6PdkXxlCa+JgBIrMhze6YXgEcDdyRypvquCUNAz4BXJfmRRMfbye65fPdyklhKLC8ML8ilbWKQRGxKk2/BAxqZDBVkTQSGAPMpwWOOXWlPAasAeYCvwdei4h3UpVm+5xfBVwAbErzA2ju460J4F5JC9Otf6CbPt895joFa5yICElNd26ypN2BnwDnRcTr2Y/ITLMec0S8C4yW1A+4E/hwg0OqjKQTgDURsVDSUY2Op86OjIiVkj4IzJW0uLhwez7frdxSaPXbaqyWNBggva9pcDzdStKOZAnh5oj4aSpu6mMuiojXgPuBw4F+kmo/AJvpc34EcKKkF8i6f48GrqZ5jzcXESvT+xqy5H8o3fT5buWk0Oq31ZgDTE7Tk4HZDYylW6V+5euBZyLiisKipj1mAEltqYWApF2BY8jGU+4HTknVmua4I+JrETEsIkaS/f3eFxFn0KTHWyNpN0l71KaBY4En6abPd0tf0SxpIlmfZO22Gpc2OKRKSLoFOIrs9rqrgX8G/i8wCxgBLANOjYj2g9G9kqQjgV8DT/BeX/NFZOMKTXnMAJIOIhtg7EP2g29WRFwiaT+yX9L9gUeBT0fEW42LtPul7qPzI+KEZj/edHx3ptm+wI8j4lJJA+iGz3dLJwUzM3u/Vu4+MjOzdpwUzMws56RgZmY5JwUzM8s5KZiZWc5JwawESRs6r/W++kfV7tpp1ps4KZiZWc5JwawLUgvgAUl3SFos6eZ0BXXt+RyLJT0C/G1hnd3SMy0eTvf9n5TKr5b0T2n6OEm/kuS/SWso3xDPrOvGAB8BXgQeBI5IDzr5Ptn9d5YAtxXq/yPZLRg+m25D8bCkXwJfA34n6dfANcDEiNiEWQP5V4lZ1z0cESvSF/hjwEiyu5E+HxHPRXabgB8V6h8LTEu3tH4A2AUYEREbgc+T3eL62oj4fR2PwaxDbimYdV3xPjrv0vnfkYCTI+LZDpZ9FHgFGNJNsZltF7cUzLrHYmCkpA+l+dMLy34BfKkw9jAmve8DfIWsO2qCpMPqGK9Zh5wUzLpBRLwJTAXuTgPNxXvZf4Ps0ZiLJD0FfKNwe+/zI+JFsucIXydplzqHbvY+vkuqmZnl3FIwM7Ock4KZmeWcFMzMLOekYGZmOScFMzPLOSmYmVnOScHMzHL/H7nTFoyDHBwwAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-IAMedHdq59",
        "colab_type": "text"
      },
      "source": [
        "De los resultados obtenidos puede verse que el desempeño de la RNN con mecanismos atencionales es mucho mejor. Si bien para las cadenas de largo 30 y largo 50 ninguno de los dos modelos utilizados logró predecir secuencias invertidas exactas. La red con mecanismo atencionales presenta un error promedio en la secuencia mucho más bajo que la contra parte sin atención.\n",
        "\n",
        "Para efectos del dataset de juguete inversor de secuencias se tiene que la red recurrente con atención es la ganadora, por lejos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M7TzleUXsKo",
        "colab_type": "text"
      },
      "source": [
        "## <u>Clasificador Secuencia</u>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETMlAH_wfJGD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8a95777f-71d7-464e-9e09-a02a0fa8822b"
      },
      "source": [
        "def split_shuffle(X,Y,n_rows,p,semilla=0):\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "    x_test = []\n",
        "    y_test = []\n",
        "    np.random.seed(semilla)\n",
        "    indices_c1 = np.arange(0,int(n_rows/2))\n",
        "    samples_c1 = np.random.choice(indices_c1,size=int(p*n_rows*0.5),replace=False)\n",
        "    indices_c2 = np.arange(int(n_rows/2),n_rows)\n",
        "    samples_c2 = np.random.choice(indices_c2,size=int(p*n_rows*0.5),replace=False)\n",
        "    test_index = np.append(samples_c1,samples_c2)\n",
        "    train_index = np.array([x for x in range(n_rows) if x not in test_index])\n",
        "\n",
        "    np.random.shuffle(test_index)\n",
        "    np.random.shuffle(train_index)\n",
        "\n",
        "    for index in train_index:\n",
        "        x_train.append(x[index])\n",
        "        y_train.append(y[index])\n",
        "    \n",
        "    for index in test_index:\n",
        "        x_test.append(x[index])\n",
        "        y_test.append(y[index])\n",
        "\n",
        "\n",
        "    return np.array(x_train),np.array(y_train),np.array(x_test),np.array(y_test)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  3  5  6  7 10 14 16 17 18] [ 2  8  4  9  1 13 15 11 12 19]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9mZWYgNfR-O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "478b6d09-71f4-45c2-eea0-a43a4873e0a7"
      },
      "source": [
        "p = 0.5\n",
        "n_rows = 26\n",
        "\n",
        "np.random.seed(10)\n",
        "indices_c1 = np.arange(0,int(n_rows/2))\n",
        "samples_c1 = np.random.choice(indices_c1,size=int(p*n_rows*0.5),replace=False)\n",
        "indices_c2 = np.arange(int(n_rows/2),n_rows)\n",
        "samples_c2 = np.random.choice(indices_c2,size=int(p*n_rows*0.5),replace=False)\n",
        "test_index = np.append(samples_c1,samples_c2)\n",
        "print(test_index)\n",
        "np.random.shuffle(test_index)\n",
        "print(test_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 3  7 11  6  8  2 18 14 20 15 24 25]\n",
            "[ 3 24 11 15 25 14  2 18  6  7  8 20]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5w64n5Uhz0r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d981ee73-ab8a-4be3-d99b-baecc53b95d5"
      },
      "source": [
        "not_include = [1,3,5,7,9]\n",
        "include = [x for x in range(10) if x not in not_include]\n",
        "print(include)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 2, 4, 6, 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ANqbLUJXqmA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0f096444-81f2-451b-fdf4-18faff3f3ac9"
      },
      "source": [
        "def es_creciente(seq):\n",
        "    comp = seq[0]\n",
        "    for i in range(1,len(seq)):\n",
        "        if seq[i] < comp:\n",
        "            return False\n",
        "        comp = seq[i]\n",
        "    return True\n",
        "\n",
        "def sequence(total,unique,crec = False):\n",
        "    secuencia = [x for x in np.random.choice(a=unique,size=total,replace=False)]\n",
        "    if crec:\n",
        "        secuencia.sort()\n",
        "        return secuencia\n",
        "    else:\n",
        "        while es_creciente(secuencia):\n",
        "            secuencia = [x for x in np.random.choice(a=unique,size=total,replace=False)]\n",
        "        return secuencia\n",
        "\n",
        "def oh_encode_x(secuencia,unique):\n",
        "    '''\n",
        "    Crea N vectores de largo unique\n",
        "    para cada elemento de la secuencia (N en total)\n",
        "    al vector correspondiente le pone el valor 1 en la posicion del elemento\n",
        "    seq = [2,3], largo 2 pero digamos que se hizo de 5 elem unicos\n",
        "    output:  [[0,0,1,0,0]\n",
        "              [0,0,0,1,0]]\n",
        "    '''\n",
        "    encoding = list()\n",
        "    for valor in secuencia:\n",
        "        vector = [0 for _ in range(unique)]\n",
        "        vector[valor] = 1\n",
        "        encoding.append(vector)\n",
        "    return np.array(encoding)\n",
        "\n",
        "def oh_decode_x(secuencia):\n",
        "    return [np.argmax(vector) for vector in secuencia]\n",
        "\n",
        "def oh_decode_y(elem,options):\n",
        "    return options[np.argmax(elem)]\n",
        "\n",
        "def oh_encode_y(length,unique,tag):\n",
        "    encoding = list()\n",
        "    for valor in range(length):\n",
        "        vector = [0 for _ in range(unique)]\n",
        "        if tag == \"crec\":\n",
        "            vector[0] = 1\n",
        "        else:\n",
        "            vector[1] = 1\n",
        "        encoding.append(vector)\n",
        "    return np.array(encoding)\n",
        "\n",
        "def generar_par(total,unique,crec):\n",
        "    secuencia = sequence(total,unique,crec)\n",
        "    if crec:\n",
        "        tag = \"crec\"\n",
        "    else:\n",
        "        tag = \"ncrec\"\n",
        "    x = oh_encode_x(secuencia,unique)\n",
        "    y = oh_encode_y(total,unique,tag)\n",
        "    x = x.reshape(1,x.shape[0],x.shape[1])\n",
        "    y = y.reshape(1,y.shape[0],y.shape[1])\n",
        "    return x,y,secuencia\n",
        "\n",
        "\n",
        "def generate_dataset(largo,unique,n_rows): #Que n_rows sea divisible por 2\n",
        "    dataset_x = list()\n",
        "    dataset_y = list()\n",
        "    seq_crec = list()\n",
        "    seq_dec = list()\n",
        "    for _ in range(int(n_rows/2)): #Mitad creciente, mitad decreciente\n",
        "        x,y,sec = generar_par(largo,unique,True)\n",
        "        dataset_x.append(x)\n",
        "        dataset_y.append(y)\n",
        "        seq_crec.append(sec)\n",
        "    unique_crec = [list(x) for x in set(tuple(x) for x in seq_crec)]\n",
        "\n",
        "    for _ in range(int(n_rows/2),n_rows):\n",
        "        x,y,sec = generar_par(largo,unique,False)\n",
        "        dataset_x.append(x)\n",
        "        dataset_y.append(y)\n",
        "        seq_dec.append(sec)  \n",
        "\n",
        "    unique_dec = [list(x) for x in set(tuple(x) for x in seq_dec)]\n",
        "\n",
        "    stackx = np.vstack(tuple(dataset_x))\n",
        "    stacky = np.vstack(tuple(dataset_y))\n",
        "\n",
        "    return stackx, stacky,unique_crec,unique_dec\n",
        "\n",
        "\n",
        "def split_shuffle(x,y,n_rows,p,semilla=0):\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "    x_test = []\n",
        "    y_test = []\n",
        "    np.random.seed(semilla)\n",
        "    indices_c1 = np.arange(0,int(n_rows/2))\n",
        "    samples_c1 = np.random.choice(indices_c1,size=int(p*n_rows*0.5),replace=False)\n",
        "    indices_c2 = np.arange(int(n_rows/2),n_rows)\n",
        "    samples_c2 = np.random.choice(indices_c2,size=int(p*n_rows*0.5),replace=False)\n",
        "    test_index = np.append(samples_c1,samples_c2)\n",
        "    train_index = np.array([w for w in range(n_rows) if w not in test_index])\n",
        "\n",
        "    np.random.shuffle(test_index)\n",
        "    np.random.shuffle(train_index)\n",
        "\n",
        "    for index in train_index:\n",
        "        x_train.append(x[index])\n",
        "        y_train.append(y[index])\n",
        "    \n",
        "    for index in test_index:\n",
        "        x_test.append(x[index])\n",
        "        y_test.append(y[index])\n",
        "\n",
        "\n",
        "    return np.array(x_train),np.array(y_train),np.array(x_test),np.array(y_test)\n",
        "\n",
        "\n",
        "\n",
        "seq_length = 5\n",
        "n_unique = 100\n",
        "rows = 10000\n",
        "options = [\"crec\",\"ncrec\"]\n",
        "X2_5, Y2_5, crc,drc = generate_dataset(seq_length,n_unique,rows)\n",
        "\n",
        "print(\"X:\",X2_5.shape,\"Y:\",Y2_5.shape)\n",
        "print(\"Secuencias crecientes unicas:\",len(crc),\"de:\",int(rows/2))\n",
        "print(\"Secuencias no crecientes unicas:\",len(drc),\"de:\",int(rows/2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X: (10000, 5, 100) Y: (10000, 5, 100)\n",
            "Secuencias crecientes unicas: 5000 de: 5000\n",
            "Secuencias no crecientes unicas: 5000 de: 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGTcdCy2kpcJ",
        "colab_type": "text"
      },
      "source": [
        "### Cadenas de Largo 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhuHMxI3p80p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "2a5aefe9-fcb3-4315-ac41-0d9dab9d5dc1"
      },
      "source": [
        "#Pruebas cadenas de largo 5\n",
        "\n",
        "def evaluar(real,prediccion):\n",
        "    etiqueta = np.argmax(real[0]) #se codifican todos igual asi que solo vemos el primer timestep\n",
        "    label_0 = 0\n",
        "    label_1 = 0\n",
        "    for vector in prediccion:\n",
        "        if np.argmax(vector) == 0:\n",
        "            label_0 += 1\n",
        "        else:\n",
        "            label_1 += 1\n",
        "    \n",
        "    if label_0 >= label_1:\n",
        "        label_final = 0\n",
        "    else:\n",
        "        label_final = 1\n",
        "    return etiqueta == label_final\n",
        "\n",
        "\n",
        "x_train,y_train,x_test,y_test = split_shuffle(X2_5,Y2_5,rows,0.3)\n",
        "\n",
        "model_5 = Sequential()\n",
        "model_5.add(GRU(units=150,input_shape=(5,n_unique)))\n",
        "model_5.add(RepeatVector(5))\n",
        "model_5.add(GRU(units=150,return_sequences=True))\n",
        "model_5.add(TimeDistributed(Dense(n_unique,activation=\"softmax\")))\n",
        "model_5.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "#Train\n",
        "model_5.fit(x_train,y_train,batch_size=32,epochs=10,verbose=1)\n",
        "\n",
        "#Una vez termina el entrenamiento, se hacen las predicciones\n",
        "total = x_test.shape[0]\n",
        "correctos = 0\n",
        "y_pred = model_5.predict(x_test,verbose=0)\n",
        "\n",
        "aciertos = 0\n",
        "total = y_test.shape[0]\n",
        "for t,p in zip(y_test,y_pred):\n",
        "    if evaluar(t,p):\n",
        "        aciertos += 1\n",
        "print(\" \")\n",
        "print(\"Accuracy S.A largo 5: \", aciertos/total)\n",
        "print(\" \")\n",
        "\n",
        "\n",
        "model_5 = Sequential()\n",
        "model_5.add(GRU(units=150,input_shape=(5,n_unique),return_sequences=True))\n",
        "model_5.add(AttentionDecoder(150,n_unique))\n",
        "model_5.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "#Train\n",
        "model_5.fit(x_train,y_train,batch_size=32,epochs=10,verbose=1)\n",
        "\n",
        "#Una vez termina el entrenamiento, se hacen las predicciones\n",
        "total = x_test.shape[0]\n",
        "correctos = 0\n",
        "y_pred = model_5.predict(x_test,verbose=0)\n",
        "\n",
        "aciertos = 0\n",
        "total = y_test.shape[0]\n",
        "for t,p in zip(y_test,y_pred):\n",
        "    if evaluar(t,p):\n",
        "        aciertos += 1\n",
        "print(\" \")\n",
        "print(\"Accuracy C.A largo 5: \", aciertos/total)\n",
        "print(\" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "5600/5600 [==============================] - 8s 1ms/step - loss: 0.9745 - accuracy: 0.6675\n",
            "Epoch 2/10\n",
            "5600/5600 [==============================] - 8s 1ms/step - loss: 0.2748 - accuracy: 0.8972\n",
            "Epoch 3/10\n",
            "5600/5600 [==============================] - 8s 1ms/step - loss: 0.1656 - accuracy: 0.9435\n",
            "Epoch 4/10\n",
            "5600/5600 [==============================] - 7s 1ms/step - loss: 0.1270 - accuracy: 0.9554\n",
            "Epoch 5/10\n",
            "5600/5600 [==============================] - 7s 1ms/step - loss: 0.1084 - accuracy: 0.9620\n",
            "Epoch 6/10\n",
            "5600/5600 [==============================] - 8s 1ms/step - loss: 0.0969 - accuracy: 0.9674\n",
            "Epoch 7/10\n",
            "5600/5600 [==============================] - 8s 1ms/step - loss: 0.0899 - accuracy: 0.9701\n",
            "Epoch 8/10\n",
            "5600/5600 [==============================] - 7s 1ms/step - loss: 0.0814 - accuracy: 0.9728\n",
            "Epoch 9/10\n",
            "5600/5600 [==============================] - 7s 1ms/step - loss: 0.0734 - accuracy: 0.9745\n",
            "Epoch 10/10\n",
            "5600/5600 [==============================] - 7s 1ms/step - loss: 0.0664 - accuracy: 0.9776\n",
            " \n",
            "Accuracy S.A largo 5:  0.9583333333333334\n",
            " \n",
            "Epoch 1/10\n",
            "5600/5600 [==============================] - 14s 3ms/step - loss: 0.9758 - accuracy: 0.6830\n",
            "Epoch 2/10\n",
            "5600/5600 [==============================] - 13s 2ms/step - loss: 0.3544 - accuracy: 0.8471\n",
            "Epoch 3/10\n",
            "5600/5600 [==============================] - 13s 2ms/step - loss: 0.2131 - accuracy: 0.9170\n",
            "Epoch 4/10\n",
            "5600/5600 [==============================] - 13s 2ms/step - loss: 0.1386 - accuracy: 0.9526\n",
            "Epoch 5/10\n",
            "5600/5600 [==============================] - 13s 2ms/step - loss: 0.1243 - accuracy: 0.9574\n",
            "Epoch 6/10\n",
            "5600/5600 [==============================] - 13s 2ms/step - loss: 0.1019 - accuracy: 0.9666\n",
            "Epoch 7/10\n",
            "5600/5600 [==============================] - 13s 2ms/step - loss: 0.0865 - accuracy: 0.9715\n",
            "Epoch 8/10\n",
            "5600/5600 [==============================] - 13s 2ms/step - loss: 0.0748 - accuracy: 0.9773\n",
            "Epoch 9/10\n",
            "5600/5600 [==============================] - 13s 2ms/step - loss: 0.0715 - accuracy: 0.9773\n",
            "Epoch 10/10\n",
            "5600/5600 [==============================] - 13s 2ms/step - loss: 0.0623 - accuracy: 0.9799\n",
            " \n",
            "Accuracy C.A largo 5:  0.97\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mehsOF5WkssE",
        "colab_type": "text"
      },
      "source": [
        "### Cadenas de Largo 30 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im_vaIikkvcB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "1725b038-826a-4633-c001-084709b2ab91"
      },
      "source": [
        "seq_length = 30\n",
        "n_unique = 100\n",
        "rows = 8000\n",
        "options = [\"crec\",\"ncrec\"]\n",
        "X2_30, Y2_30, crc,drc = generate_dataset(seq_length,n_unique,rows)\n",
        "\n",
        "print(\"X:\",X2_30.shape,\"Y:\",Y2_30.shape)\n",
        "print(\"Secuencias crecientes unicas:\",len(crc),\"de:\",int(rows/2))\n",
        "print(\"Secuencias no crecientes unicas:\",len(drc),\"de:\",int(rows/2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X: (8000, 30, 100) Y: (8000, 30, 100)\n",
            "Secuencias crecientes unicas: 4000 de: 4000\n",
            "Secuencias no crecientes unicas: 4000 de: 4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5g_b55Mk8yC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "d9b4ee13-6e04-4042-e5f6-e1b6efab1b47"
      },
      "source": [
        "x_train,y_train,x_test,y_test = split_shuffle(X2_30,Y2_30,rows,0.3)\n",
        "\n",
        "model_30 = Sequential()\n",
        "model_30.add(GRU(units=150,input_shape=(30,n_unique)))\n",
        "model_30.add(RepeatVector(30))\n",
        "model_30.add(GRU(units=150,return_sequences=True))\n",
        "model_30.add(TimeDistributed(Dense(n_unique,activation=\"softmax\")))\n",
        "model_30.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "#Train\n",
        "model_30.fit(x_train,y_train,batch_size=32,epochs=10,verbose=1)\n",
        "\n",
        "#Una vez termina el entrenamiento, se hacen las predicciones\n",
        "total = x_test.shape[0]\n",
        "correctos = 0\n",
        "y_pred = model_30.predict(x_test,verbose=0)\n",
        "\n",
        "aciertos = 0\n",
        "total = y_test.shape[0]\n",
        "for t,p in zip(y_test,y_pred):\n",
        "    if evaluar(t,p):\n",
        "        aciertos += 1\n",
        "print(\" \")\n",
        "print(\"Accuracy S.A largo 30: \", aciertos/total)\n",
        "print(\" \")\n",
        "\n",
        "\n",
        "model_30 = Sequential()\n",
        "model_30.add(GRU(units=150,input_shape=(30,n_unique),return_sequences=True))\n",
        "model_30.add(AttentionDecoder(150,n_unique))\n",
        "model_30.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "#Train\n",
        "model_30.fit(x_train,y_train,batch_size=32,epochs=10,verbose=1)\n",
        "\n",
        "#Una vez termina el entrenamiento, se hacen las predicciones\n",
        "total = x_test.shape[0]\n",
        "correctos = 0\n",
        "y_pred = model_30.predict(x_test,verbose=0)\n",
        "\n",
        "aciertos = 0\n",
        "total = y_test.shape[0]\n",
        "for t,p in zip(y_test,y_pred):\n",
        "    if evaluar(t,p):\n",
        "        aciertos += 1\n",
        "print(\" \")\n",
        "print(\"Accuracy C.A largo 30: \", aciertos/total)\n",
        "print(\" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "5600/5600 [==============================] - 37s 7ms/step - loss: 0.5627 - accuracy: 0.8468\n",
            "Epoch 2/10\n",
            "5600/5600 [==============================] - 36s 6ms/step - loss: 0.0084 - accuracy: 0.9984\n",
            "Epoch 3/10\n",
            "5600/5600 [==============================] - 36s 6ms/step - loss: 8.5679e-04 - accuracy: 0.9998\n",
            "Epoch 4/10\n",
            "5600/5600 [==============================] - 36s 6ms/step - loss: 0.0078 - accuracy: 0.9984\n",
            "Epoch 5/10\n",
            "5600/5600 [==============================] - 36s 6ms/step - loss: 0.0020 - accuracy: 0.9994\n",
            "Epoch 6/10\n",
            "5600/5600 [==============================] - 36s 6ms/step - loss: 0.0011 - accuracy: 0.9998\n",
            "Epoch 7/10\n",
            "5600/5600 [==============================] - 36s 6ms/step - loss: 1.5969e-04 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "5600/5600 [==============================] - 35s 6ms/step - loss: 1.1383e-04 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "5600/5600 [==============================] - 36s 6ms/step - loss: 8.7434e-05 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "5600/5600 [==============================] - 35s 6ms/step - loss: 6.9914e-05 - accuracy: 1.0000\n",
            " \n",
            "Accuracy S.A largo 30:  0.9995833333333334\n",
            " \n",
            "Epoch 1/10\n",
            "5600/5600 [==============================] - 63s 11ms/step - loss: 0.7125 - accuracy: 0.7362\n",
            "Epoch 2/10\n",
            "5600/5600 [==============================] - 61s 11ms/step - loss: 0.1904 - accuracy: 0.9322\n",
            "Epoch 3/10\n",
            "5600/5600 [==============================] - 61s 11ms/step - loss: 0.0342 - accuracy: 0.9894\n",
            "Epoch 4/10\n",
            "5600/5600 [==============================] - 62s 11ms/step - loss: 0.0095 - accuracy: 0.9978\n",
            "Epoch 5/10\n",
            "5600/5600 [==============================] - 61s 11ms/step - loss: 0.0041 - accuracy: 0.9988\n",
            "Epoch 6/10\n",
            "5600/5600 [==============================] - 61s 11ms/step - loss: 0.0084 - accuracy: 0.9982\n",
            "Epoch 7/10\n",
            "5600/5600 [==============================] - 61s 11ms/step - loss: 0.0044 - accuracy: 0.9984\n",
            "Epoch 8/10\n",
            "5600/5600 [==============================] - 61s 11ms/step - loss: 0.0020 - accuracy: 0.9991\n",
            "Epoch 9/10\n",
            "5600/5600 [==============================] - 61s 11ms/step - loss: 0.0015 - accuracy: 0.9996\n",
            "Epoch 10/10\n",
            "5600/5600 [==============================] - 60s 11ms/step - loss: 0.0216 - accuracy: 0.9944\n",
            " \n",
            "Accuracy C.A largo 30:  0.9941666666666666\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB5o4uTgqV3q",
        "colab_type": "text"
      },
      "source": [
        "### Cadenas de Largo 50 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUel0sH3qb3L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "2ad0326c-b14e-4a3b-f91b-65ca0792cac8"
      },
      "source": [
        "seq_length = 50\n",
        "n_unique = 100\n",
        "rows = 8000\n",
        "options = [\"crec\",\"ncrec\"]\n",
        "X2_50, Y2_50, crc,drc = generate_dataset(seq_length,n_unique,rows)\n",
        "\n",
        "print(\"X:\",X2_50.shape,\"Y:\",Y2_50.shape)\n",
        "print(\"Secuencias crecientes unicas:\",len(crc),\"de:\",int(rows/2))\n",
        "print(\"Secuencias no crecientes unicas:\",len(drc),\"de:\",int(rows/2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X: (8000, 50, 100) Y: (8000, 50, 100)\n",
            "Secuencias crecientes unicas: 4000 de: 4000\n",
            "Secuencias no crecientes unicas: 4000 de: 4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyzBTzInrF-5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "84a99dbf-ff36-4d1e-9185-0ba01334eb51"
      },
      "source": [
        "x_train,y_train,x_test,y_test = split_shuffle(X2_50,Y2_50,rows,0.3)\n",
        "\n",
        "model_50 = Sequential()\n",
        "model_50.add(GRU(units=150,input_shape=(50,n_unique)))\n",
        "model_50.add(RepeatVector(50))\n",
        "model_50.add(GRU(units=150,return_sequences=True))\n",
        "model_50.add(TimeDistributed(Dense(n_unique,activation=\"softmax\")))\n",
        "model_50.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "#Train\n",
        "model_50.fit(x_train,y_train,batch_size=32,epochs=10,verbose=1)\n",
        "\n",
        "#Una vez termina el entrenamiento, se hacen las predicciones\n",
        "total = x_test.shape[0]\n",
        "correctos = 0\n",
        "y_pred = model_50.predict(x_test,verbose=0)\n",
        "\n",
        "aciertos = 0\n",
        "total = y_test.shape[0]\n",
        "for t,p in zip(y_test,y_pred):\n",
        "    if evaluar(t,p):\n",
        "        aciertos += 1\n",
        "print(\" \")\n",
        "print(\"Accuracy S.A largo 50: \", aciertos/total)\n",
        "print(\" \")\n",
        "\n",
        "\n",
        "model_50 = Sequential()\n",
        "model_50.add(GRU(units=150,input_shape=(50,n_unique),return_sequences=True))\n",
        "model_50.add(AttentionDecoder(150,n_unique))\n",
        "model_50.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "#Train\n",
        "model_50.fit(x_train,y_train,batch_size=32,epochs=10,verbose=1)\n",
        "\n",
        "#Una vez termina el entrenamiento, se hacen las predicciones\n",
        "total = x_test.shape[0]\n",
        "correctos = 0\n",
        "y_pred = model_50.predict(x_test,verbose=0)\n",
        "\n",
        "aciertos = 0\n",
        "total = y_test.shape[0]\n",
        "for t,p in zip(y_test,y_pred):\n",
        "    if evaluar(t,p):\n",
        "        aciertos += 1\n",
        "print(\" \")\n",
        "print(\"Accuracy C.A largo 50: \", aciertos/total)\n",
        "print(\" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "5600/5600 [==============================] - 57s 10ms/step - loss: 0.4362 - accuracy: 0.9307\n",
            "Epoch 2/10\n",
            "5600/5600 [==============================] - 55s 10ms/step - loss: 0.0022 - accuracy: 0.9997\n",
            "Epoch 3/10\n",
            "5600/5600 [==============================] - 55s 10ms/step - loss: 1.9954e-04 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "5600/5600 [==============================] - 55s 10ms/step - loss: 1.0219e-04 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "5600/5600 [==============================] - 55s 10ms/step - loss: 7.0191e-05 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "5600/5600 [==============================] - 55s 10ms/step - loss: 5.5388e-05 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "5600/5600 [==============================] - 54s 10ms/step - loss: 4.5650e-05 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "5600/5600 [==============================] - 55s 10ms/step - loss: 3.8886e-05 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "5600/5600 [==============================] - 55s 10ms/step - loss: 3.3860e-05 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "5600/5600 [==============================] - 55s 10ms/step - loss: 2.9787e-05 - accuracy: 1.0000\n",
            " \n",
            "Accuracy S.A largo 50:  1.0\n",
            " \n",
            "Epoch 1/10\n",
            "5600/5600 [==============================] - 98s 17ms/step - loss: 0.6263 - accuracy: 0.7799\n",
            "Epoch 2/10\n",
            "5600/5600 [==============================] - 96s 17ms/step - loss: 0.1266 - accuracy: 0.9610\n",
            "Epoch 3/10\n",
            "5600/5600 [==============================] - 96s 17ms/step - loss: 0.1217 - accuracy: 0.9629\n",
            "Epoch 4/10\n",
            "5600/5600 [==============================] - 96s 17ms/step - loss: 0.0291 - accuracy: 0.9903\n",
            "Epoch 5/10\n",
            "5600/5600 [==============================] - 96s 17ms/step - loss: 0.0016 - accuracy: 0.9996\n",
            "Epoch 6/10\n",
            "5600/5600 [==============================] - 96s 17ms/step - loss: 8.6413e-04 - accuracy: 0.9997\n",
            "Epoch 7/10\n",
            "5600/5600 [==============================] - 96s 17ms/step - loss: 1.0299e-04 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "5600/5600 [==============================] - 98s 18ms/step - loss: 7.2527e-05 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "5600/5600 [==============================] - 96s 17ms/step - loss: 5.6282e-05 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "5600/5600 [==============================] - 97s 17ms/step - loss: 4.5173e-05 - accuracy: 1.0000\n",
            " \n",
            "Accuracy C.A largo 50:  1.0\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDKSG_MJqyuL",
        "colab_type": "text"
      },
      "source": [
        "En este caso se tiene que el desempeño de ambos modelos es bueno. No se nota ventaja al utilizar atención. Esto puede deberse a que para determinar la etiqueta, analizar la secuencia entera o por partes es igual de válido y efectivo. Por temas de tiempo se declara a la RNN sin atención como la ganadora porque tarda menos tiempo en entrenar, pero en desempeño ambas son igual de buenas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-xK47UpqzMF",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Real 1: Spanish to English\n",
        "\n",
        "Si bien en la presentación se dijo que trabajaríamos con traducción español a ingles del parlamento europeo. Por temas de no utilizar un lenguaje muy técnico y formal se optó por utilizar una dataset de [esta fuente](http://www.manythings.org/anki/) que contiene oraciones en español y su traducción al inglés. El contexto sigue siendo seq2seq.\n",
        "\n",
        "Para una gran parte del trabajo se utilizó [este tutorial de tensorflow](https://www.tensorflow.org/tutorials/text/nmt_with_attention) que introduce mecanismo de atención en traducción de texto. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OQpkAeEQljN",
        "colab_type": "text"
      },
      "source": [
        "## Modelo Sin Atencion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCwgWvzUQp2R",
        "colab_type": "text"
      },
      "source": [
        "### Preprocesamiento \n",
        "\n",
        "En la parte de preprocesamiento se harán los siguientes pasos:\n",
        "\n",
        "1. Se separarán todas las palabras y caracteres especiales de las oraciones en ambos idiomas. Por ejemplo: \"¿Cómo estás?\" $\\rightarrow$ \"¿ Cómo estás ?\" Esto es para ayudar a la identificación de tokens en la secuencia. \n",
        "\n",
        "2. Como el español tiene símbolos extra al inglés (como ¿ y ¡) se codificarán estas oraciones en formato unicode.\n",
        "\n",
        "3. Después de eso se creará el dataset donde el input será el idioma español y el output será el idioma inglés.\n",
        "\n",
        "4. A cada columna del dataset se le aplica un tokenizador para representar la oración como una cadena de tokens. Esto permitirá una representación más fácil de entender para la red. Además de un padding para que todos los inputs tengan la misma dimensión, el padding es agregar el token 0 (no hay nada) hasta que la oración tenga el largo de la oración más larga detectada en el lenguaje a analizar.\n",
        "\n",
        "> El tokenizador le asigna una *id* a cada palabra/símbolo que se encuentre en el lenguaje sobre el que trabaja. Y luego de ese fit en el lenguaje de entrada se pueden convertir los textos en secuencias de tokens. La representación para la RNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EneQu7VQuyN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9f816c74-b13a-4670-80a6-bbc9bcdb0bb1"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "\n",
        "# Download the file\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\"\n",
        "\n",
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  return w"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V73dsxEQy00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "\n",
        "  return zip(*word_pairs)\n",
        "\n",
        "en, sp = create_dataset(path_to_file, None)\n",
        "\n",
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer\n",
        "\n",
        "def load_dataset(path, num_examples=None):\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\n",
        "\n",
        "# Se usan 50000 ejemplos por temas de tiempo.\n",
        "num_examples = 50000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# La oracion mas larga (aqui ya tienen padding asi que todo tiene el largo mas largo)\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2,random_state=0)\n",
        "\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OUNKDKtQ2zK",
        "colab_type": "text"
      },
      "source": [
        "### Modelo \n",
        "\n",
        "1. Se empieza con una capa de Embedding lo que llevará la secuencia de tokens a un representación vectorial densa. En esta caso el output del embedding es un espacio cuya dimensión corresponde a la cantidad de unidades GRU que hay en la siguiente capa.\n",
        "\n",
        "2. Como se dijo en la presentación se opta por GRU en vez de LSTM porque tienen desempeños similares, pero es más eficiente computacionalmente.\n",
        "\n",
        "3. Después hay una capa *RepeatVector* que repite el input una cantidad *n* de veces, esto permite crear temporalidad a los datos.\n",
        "\n",
        "4. Después hay otra capa GRU y de esta se aplica una Time Distributed Dense Layer. Como se pasan múltiples instantes de tiempo, esto permitirá aplicar la capa Dense a cada instante. Se usa con conjunto con *return_sequences=True*\n",
        "\n",
        "5. Se utiliza una capa softmax ya que la forma de abordar estos problemas es como si se estuviera abordando un problema de clasificación multilabel pero las distribuciones se comparan de forma sparse. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YZUHpZFQ5yO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "25a72286-daf4-470e-9db4-c4f08c54923a"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import GRU, LSTM, Dense, TimeDistributed, RepeatVector, Embedding\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
        "    model.add(GRU(units))\n",
        "    model.add(RepeatVector(out_timesteps))\n",
        "    model.add(GRU(units, return_sequences=True))\n",
        "    model.add(TimeDistributed(Dense(out_vocab, activation='softmax'))) #many to many\n",
        "    return model\n",
        "\n",
        "model = build_model(vocab_inp_size, vocab_tar_size, max_length_inp, max_length_targ, 512)\n",
        "adam = optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=adam, loss='sparse_categorical_crossentropy')\n",
        "\n",
        "filename = 'model.h1.BestWAModel'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "history = model.fit(input_tensor_train, target_tensor_train.reshape(target_tensor_train.shape[0], target_tensor_train.shape[1], 1), \n",
        "          epochs=30, batch_size=512, \n",
        "          callbacks=[checkpoint], verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "40000/40000 [==============================] - 12s 301us/step - loss: 3.7929\n",
            "Epoch 2/30\n",
            "  512/40000 [..............................] - ETA: 10s - loss: 3.0576"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
            "  'skipping.' % (self.monitor), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 11s 287us/step - loss: 2.9304\n",
            "Epoch 3/30\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 2.8353\n",
            "Epoch 4/30\n",
            "40000/40000 [==============================] - 12s 293us/step - loss: 2.7750\n",
            "Epoch 5/30\n",
            "40000/40000 [==============================] - 12s 288us/step - loss: 2.7052\n",
            "Epoch 6/30\n",
            "40000/40000 [==============================] - 12s 292us/step - loss: 2.6063\n",
            "Epoch 7/30\n",
            "40000/40000 [==============================] - 11s 286us/step - loss: 2.5092\n",
            "Epoch 8/30\n",
            "40000/40000 [==============================] - 11s 287us/step - loss: 2.4271\n",
            "Epoch 9/30\n",
            "40000/40000 [==============================] - 11s 284us/step - loss: 2.3507\n",
            "Epoch 10/30\n",
            "40000/40000 [==============================] - 11s 287us/step - loss: 2.2844\n",
            "Epoch 11/30\n",
            "40000/40000 [==============================] - 11s 285us/step - loss: 2.2155\n",
            "Epoch 12/30\n",
            "40000/40000 [==============================] - 12s 289us/step - loss: 2.1461\n",
            "Epoch 13/30\n",
            "40000/40000 [==============================] - 11s 287us/step - loss: 2.0934\n",
            "Epoch 14/30\n",
            "40000/40000 [==============================] - 11s 286us/step - loss: 2.0063\n",
            "Epoch 15/30\n",
            "40000/40000 [==============================] - 11s 284us/step - loss: 1.9273\n",
            "Epoch 16/30\n",
            "40000/40000 [==============================] - 11s 286us/step - loss: 1.8449\n",
            "Epoch 17/30\n",
            "40000/40000 [==============================] - 11s 285us/step - loss: 1.7701\n",
            "Epoch 18/30\n",
            "40000/40000 [==============================] - 11s 283us/step - loss: 1.6885\n",
            "Epoch 19/30\n",
            "40000/40000 [==============================] - 11s 284us/step - loss: 1.6106\n",
            "Epoch 20/30\n",
            "40000/40000 [==============================] - 11s 283us/step - loss: 1.5381\n",
            "Epoch 21/30\n",
            "40000/40000 [==============================] - 11s 283us/step - loss: 1.4685\n",
            "Epoch 22/30\n",
            "40000/40000 [==============================] - 11s 281us/step - loss: 1.3985\n",
            "Epoch 23/30\n",
            "40000/40000 [==============================] - 11s 284us/step - loss: 1.3280\n",
            "Epoch 24/30\n",
            "40000/40000 [==============================] - 11s 281us/step - loss: 1.2672\n",
            "Epoch 25/30\n",
            "40000/40000 [==============================] - 11s 285us/step - loss: 1.1998\n",
            "Epoch 26/30\n",
            "40000/40000 [==============================] - 11s 281us/step - loss: 1.1304\n",
            "Epoch 27/30\n",
            "40000/40000 [==============================] - 11s 282us/step - loss: 1.0654\n",
            "Epoch 28/30\n",
            "40000/40000 [==============================] - 11s 284us/step - loss: 1.0032\n",
            "Epoch 29/30\n",
            "40000/40000 [==============================] - 11s 281us/step - loss: 0.9441\n",
            "Epoch 30/30\n",
            "40000/40000 [==============================] - 11s 283us/step - loss: 0.8897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REBsSYCzQ_w2",
        "colab_type": "text"
      },
      "source": [
        "Ahora se traducen los resultados y se creará una dataset de comparación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UosbDa6fRDuv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "bc843c57-4b2e-4070-839e-324102d9115c"
      },
      "source": [
        "%%time\n",
        "import pandas as pd\n",
        "def convertir(lang, tensor):\n",
        "    messate = \"\"     \n",
        "    for t in tensor:    \n",
        "        if t!=0:\n",
        "            messate += lang.index_word[t] + \" \"\n",
        "    return messate.strip()\n",
        "\n",
        "\n",
        "def get_word(n, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == n:\n",
        "            return word\n",
        "    return None\n",
        "\n",
        "preds = model.predict_classes(input_tensor_val.reshape((input_tensor_val.shape[0],input_tensor_val.shape[1])))\n",
        "\n",
        "diccio = {\"Prediccion Sin A\":[],\"Real\":[]}\n",
        "\n",
        "total = len(preds)\n",
        "contador = 0\n",
        "p_prog = 0.1\n",
        "\n",
        "for x,y in zip(preds,target_tensor_val):\n",
        "    diccio[\"Prediccion Sin A\"].append(convertir(targ_lang,x))\n",
        "    diccio[\"Real\"].append(convertir(targ_lang,y))\n",
        "    contador += 1\n",
        "    if contador/total > p_prog:\n",
        "        print(\"Progreso de:\",int(100*p_prog),\"%\")\n",
        "        p_prog += 0.1\n",
        "DataSetSinAtencion = pd.DataFrame.from_dict(diccio)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Progreso de: 10 %\n",
            "Progreso de: 20 %\n",
            "Progreso de: 30 %\n",
            "Progreso de: 40 %\n",
            "Progreso de: 50 %\n",
            "Progreso de: 60 %\n",
            "Progreso de: 70 %\n",
            "Progreso de: 80 %\n",
            "Progreso de: 89 %\n",
            "Progreso de: 99 %\n",
            "CPU times: user 5.23 s, sys: 1.24 s, total: 6.48 s\n",
            "Wall time: 6.31 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z5DTUtzRMeN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "07f473d4-5fd9-4d57-ac94-d43081400875"
      },
      "source": [
        "DataSetSinAtencion.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prediccion Sin A</th>\n",
              "      <th>Real</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>this is our room .</td>\n",
              "      <td>this is your key .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>he had a wife .</td>\n",
              "      <td>he had one daughter .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>my s the is is true .</td>\n",
              "      <td>part of his story is true .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tom never never dumb .</td>\n",
              "      <td>tom never had doubts .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>we ll nothing nothing .</td>\n",
              "      <td>we didn t learn anything .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i need a to with now .</td>\n",
              "      <td>i need a place to live .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>you can t be a joke .</td>\n",
              "      <td>you can t be a doctor .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>what s the name ?</td>\n",
              "      <td>what s your name ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>i think in . .</td>\n",
              "      <td>i m thinking about you .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>what are your parents ?</td>\n",
              "      <td>what are your duties ?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Prediccion Sin A                         Real\n",
              "0       this is our room .           this is your key .\n",
              "1          he had a wife .        he had one daughter .\n",
              "2    my s the is is true .  part of his story is true .\n",
              "3   tom never never dumb .       tom never had doubts .\n",
              "4  we ll nothing nothing .   we didn t learn anything .\n",
              "5   i need a to with now .     i need a place to live .\n",
              "6    you can t be a joke .      you can t be a doctor .\n",
              "7        what s the name ?           what s your name ?\n",
              "8           i think in . .     i m thinking about you .\n",
              "9  what are your parents ?       what are your duties ?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtJ9t7voRPZy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "eb1d4e8f-f4f6-4b29-c770-9a9e58eb0a77"
      },
      "source": [
        "print(\"Oraciones exactas predecidas Sin A:\",len(DataSetSinAtencion[DataSetSinAtencion['Prediccion Sin A'] == DataSetSinAtencion.Real]))\n",
        "print(\"Oraciones en conjunto val\",len(DataSetSinAtencion))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Oraciones exactas predecidas Sin A: 592\n",
            "Oraciones en conjunto val 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7E_sBQzRReM",
        "colab_type": "text"
      },
      "source": [
        "De un puñado de traducciones se puede ver que el modelo sin atención tiene problemas para finalizar las oraciones. Las termina antes de tiempo. Para hacer una mejor comparación, primero se hará un procedimiento similar con un modelo que utilice atención. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXalwgB2RWOW",
        "colab_type": "text"
      },
      "source": [
        "## Modelo Con Atención"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU-3ZL8VRYwt",
        "colab_type": "text"
      },
      "source": [
        "### Preprocesamiento \n",
        "\n",
        "El proceso es muy similar a lo anterior, pero esta vez se agregan dos tags a la oracion, un tag \\<start> y un tag \\<end> para delimitar la oracion. Y es porque en este modelo se irá prediciendo palabra a palabra hasta que el output sea el tag \\<end>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld7m_JQlRb8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "\n",
        "# Download the file\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\"\n",
        "\n",
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO4p-jutRf85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "\n",
        "  return zip(*word_pairs)\n",
        "\n",
        "en, sp = create_dataset(path_to_file, None)\n",
        "\n",
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer\n",
        "\n",
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\n",
        "\n",
        "# Try experimenting with the size of that dataset\n",
        "num_examples = 50000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "\n",
        "\n",
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Nb-HeoDRqIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Esto es para ver como se estructura una oracion con los tokens\n",
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))\n",
        "\n",
        "'''\n",
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHvFDCKHRx2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "example_input_batch, example_target_batch = next(iter(dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OQPA2JFR2pl",
        "colab_type": "text"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7owIM8BTR196",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8c73130f-1540-46b3-dc5b-394235626739"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))\n",
        "\n",
        "\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QchRH-8KR7AW",
        "colab_type": "text"
      },
      "source": [
        "### Bahdanau Attention\n",
        "\n",
        "La atención de Bahdanau multiplica los estados ocultos del encoder ($h_i$) con ciertos pesos ($a_i$) para formar el vector de contexto ($c$).\n",
        "\n",
        "$$\n",
        "c_t = \\sum_{s}^{T} = a_{ts}h_{s}\n",
        "$$\n",
        "\n",
        "Los pesos $a$ se obtienen mediante la aplicación de una operación *Softmax*:\n",
        "\n",
        "$$\n",
        "a_{ts} = \\frac{exp(score(h_t,\\bar{h}_{s}))}{\\sum_{s'}^{S}score(h_t,\\bar{h}_{s'})}\n",
        "$$\n",
        "\n",
        "a la atención de Bahdanau:\n",
        "\n",
        "$$\n",
        "score(h_t,\\bar{h}_{s}) = v^{T}tanh\\left(W_{1}h_t+W_{2}\\bar{h}_{s} \\right)\n",
        "$$\n",
        "\n",
        "Los pesos compartidos $W_i$ Los aprende una pequeña red neuronal, que estará entre Encoder y Decoder\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5qdRXV8R8s1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ac6b6421-e954-4607-a6e9-79eef03ef8ce"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "\n",
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp_xkfIhSAL2",
        "colab_type": "text"
      },
      "source": [
        "### Decoder\n",
        "\n",
        "Es similar al encoder, pero en este caso se le agrega la atención de Bahdanau como input y los estados ocultos del Encoder para aplicar el mecanismo atencional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSogpSYZSBM2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ee2a69d2-2cd5-47f9-c423-ad62086aec35"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights\n",
        "\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 6817)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TgXXO8dSK3I",
        "colab_type": "text"
      },
      "source": [
        "### Optimizador y función de pérdida\n",
        "\n",
        "Se utilizar Sparse Categorical Cross Entropy como la Loss ya que estos problemas los comparan a una clasificación multi label. Pero se utiliza una versión Sparse ya que la distribución de probabilidad de una oración no puede compararse a la distribución de probabilidad del lenguaje entero. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy3J7R1sSNBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)\n",
        "\n",
        "\n",
        "checkpoint_dir = '/content/drive/My Drive/ANNT2/cpp2'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"checkpoints\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qy5XMSuSSe9",
        "colab_type": "text"
      },
      "source": [
        "### Entrenamiento\n",
        "\n",
        "El entrenamiento consiste en los siguientes pasos:\n",
        "\n",
        "1. Pasar el input por el encoder.\n",
        "\n",
        "2. El output del encoder y sus estados ocultos se pasan al decoder, el que retorna la predicción y sus estados ocultos.\n",
        "\n",
        "3. El estado oculto del decoder se pasa de vuelta al modelo y la predicción se utiliza para calcular la loss.\n",
        "\n",
        "4. Se usa *teacher forcing* para decidir el siguiente input del decoder\n",
        "\n",
        ">*Teacher forcing* es utilizar como input el output del modelo en el instante anterior.\n",
        "\n",
        "5. Se calculan los gradientes, se aplica el optimizador y se hace backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-J3T_D-SUHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRa9P0g6SWqb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "600d0850-ab3a-45ea-98ba-0f1f033fa4cd"
      },
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 10 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.7101\n",
            "Epoch 1 Batch 100 Loss 2.2490\n",
            "Epoch 1 Batch 200 Loss 2.0034\n",
            "Epoch 1 Batch 300 Loss 1.9557\n",
            "Epoch 1 Batch 400 Loss 1.7105\n",
            "Epoch 1 Batch 500 Loss 1.5780\n",
            "Epoch 1 Batch 600 Loss 1.4845\n",
            "Epoch 1 Loss 1.9744\n",
            "Time taken for 1 epoch 79.26939558982849 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.4187\n",
            "Epoch 2 Batch 100 Loss 1.3429\n",
            "Epoch 2 Batch 200 Loss 1.2500\n",
            "Epoch 2 Batch 300 Loss 1.1841\n",
            "Epoch 2 Batch 400 Loss 1.1390\n",
            "Epoch 2 Batch 500 Loss 1.0574\n",
            "Epoch 2 Batch 600 Loss 0.9278\n",
            "Epoch 2 Loss 1.1818\n",
            "Time taken for 1 epoch 65.69926404953003 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.8868\n",
            "Epoch 3 Batch 100 Loss 0.7523\n",
            "Epoch 3 Batch 200 Loss 0.8383\n",
            "Epoch 3 Batch 300 Loss 0.7333\n",
            "Epoch 3 Batch 400 Loss 0.7759\n",
            "Epoch 3 Batch 500 Loss 0.7607\n",
            "Epoch 3 Batch 600 Loss 0.7669\n",
            "Epoch 3 Loss 0.7570\n",
            "Time taken for 1 epoch 65.21557068824768 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.5148\n",
            "Epoch 4 Batch 100 Loss 0.4223\n",
            "Epoch 4 Batch 200 Loss 0.4514\n",
            "Epoch 4 Batch 300 Loss 0.4800\n",
            "Epoch 4 Batch 400 Loss 0.5549\n",
            "Epoch 4 Batch 500 Loss 0.6256\n",
            "Epoch 4 Batch 600 Loss 0.5944\n",
            "Epoch 4 Loss 0.5055\n",
            "Time taken for 1 epoch 65.52829909324646 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.3539\n",
            "Epoch 5 Batch 100 Loss 0.2715\n",
            "Epoch 5 Batch 200 Loss 0.3984\n",
            "Epoch 5 Batch 300 Loss 0.4127\n",
            "Epoch 5 Batch 400 Loss 0.3594\n",
            "Epoch 5 Batch 500 Loss 0.3713\n",
            "Epoch 5 Batch 600 Loss 0.3690\n",
            "Epoch 5 Loss 0.3498\n",
            "Time taken for 1 epoch 65.57965755462646 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.2334\n",
            "Epoch 6 Batch 100 Loss 0.2208\n",
            "Epoch 6 Batch 200 Loss 0.2446\n",
            "Epoch 6 Batch 300 Loss 0.2262\n",
            "Epoch 6 Batch 400 Loss 0.2667\n",
            "Epoch 6 Batch 500 Loss 0.3648\n",
            "Epoch 6 Batch 600 Loss 0.2434\n",
            "Epoch 6 Loss 0.2491\n",
            "Time taken for 1 epoch 65.62970399856567 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.1545\n",
            "Epoch 7 Batch 100 Loss 0.1579\n",
            "Epoch 7 Batch 200 Loss 0.1982\n",
            "Epoch 7 Batch 300 Loss 0.1813\n",
            "Epoch 7 Batch 400 Loss 0.2184\n",
            "Epoch 7 Batch 500 Loss 0.2348\n",
            "Epoch 7 Batch 600 Loss 0.2492\n",
            "Epoch 7 Loss 0.1868\n",
            "Time taken for 1 epoch 65.5254545211792 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1198\n",
            "Epoch 8 Batch 100 Loss 0.0950\n",
            "Epoch 8 Batch 200 Loss 0.1856\n",
            "Epoch 8 Batch 300 Loss 0.1110\n",
            "Epoch 8 Batch 400 Loss 0.1642\n",
            "Epoch 8 Batch 500 Loss 0.1382\n",
            "Epoch 8 Batch 600 Loss 0.1133\n",
            "Epoch 8 Loss 0.1450\n",
            "Time taken for 1 epoch 65.54589033126831 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.1048\n",
            "Epoch 9 Batch 100 Loss 0.1208\n",
            "Epoch 9 Batch 200 Loss 0.1028\n",
            "Epoch 9 Batch 300 Loss 0.1427\n",
            "Epoch 9 Batch 400 Loss 0.1166\n",
            "Epoch 9 Batch 500 Loss 0.1341\n",
            "Epoch 9 Batch 600 Loss 0.1269\n",
            "Epoch 9 Loss 0.1178\n",
            "Time taken for 1 epoch 65.3635413646698 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0988\n",
            "Epoch 10 Batch 100 Loss 0.0981\n",
            "Epoch 10 Batch 200 Loss 0.1082\n",
            "Epoch 10 Batch 300 Loss 0.1155\n",
            "Epoch 10 Batch 400 Loss 0.1498\n",
            "Epoch 10 Batch 500 Loss 0.1134\n",
            "Epoch 10 Batch 600 Loss 0.1292\n",
            "Epoch 10 Loss 0.1004\n",
            "Time taken for 1 epoch 66.84373164176941 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.0689\n",
            "Epoch 11 Batch 100 Loss 0.0660\n",
            "Epoch 11 Batch 200 Loss 0.0718\n",
            "Epoch 11 Batch 300 Loss 0.0687\n",
            "Epoch 11 Batch 400 Loss 0.0816\n",
            "Epoch 11 Batch 500 Loss 0.0833\n",
            "Epoch 11 Batch 600 Loss 0.0939\n",
            "Epoch 11 Loss 0.0885\n",
            "Time taken for 1 epoch 66.21742463111877 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.0543\n",
            "Epoch 12 Batch 100 Loss 0.0634\n",
            "Epoch 12 Batch 200 Loss 0.0623\n",
            "Epoch 12 Batch 300 Loss 0.0995\n",
            "Epoch 12 Batch 400 Loss 0.0898\n",
            "Epoch 12 Batch 500 Loss 0.1020\n",
            "Epoch 12 Batch 600 Loss 0.0691\n",
            "Epoch 12 Loss 0.0794\n",
            "Time taken for 1 epoch 65.49565887451172 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.0526\n",
            "Epoch 13 Batch 100 Loss 0.0380\n",
            "Epoch 13 Batch 200 Loss 0.0500\n",
            "Epoch 13 Batch 300 Loss 0.0687\n",
            "Epoch 13 Batch 400 Loss 0.0858\n",
            "Epoch 13 Batch 500 Loss 0.0674\n",
            "Epoch 13 Batch 600 Loss 0.0708\n",
            "Epoch 13 Loss 0.0739\n",
            "Time taken for 1 epoch 65.37478160858154 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.0454\n",
            "Epoch 14 Batch 100 Loss 0.0654\n",
            "Epoch 14 Batch 200 Loss 0.0591\n",
            "Epoch 14 Batch 300 Loss 0.0759\n",
            "Epoch 14 Batch 400 Loss 0.0648\n",
            "Epoch 14 Batch 500 Loss 0.0742\n",
            "Epoch 14 Batch 600 Loss 0.0959\n",
            "Epoch 14 Loss 0.0697\n",
            "Time taken for 1 epoch 65.79597115516663 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.0719\n",
            "Epoch 15 Batch 100 Loss 0.0689\n",
            "Epoch 15 Batch 200 Loss 0.0531\n",
            "Epoch 15 Batch 300 Loss 0.0783\n",
            "Epoch 15 Batch 400 Loss 0.0638\n",
            "Epoch 15 Batch 500 Loss 0.0867\n",
            "Epoch 15 Batch 600 Loss 0.0974\n",
            "Epoch 15 Loss 0.0641\n",
            "Time taken for 1 epoch 65.57533526420593 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.0443\n",
            "Epoch 16 Batch 100 Loss 0.0526\n",
            "Epoch 16 Batch 200 Loss 0.0924\n",
            "Epoch 16 Batch 300 Loss 0.0642\n",
            "Epoch 16 Batch 400 Loss 0.0650\n",
            "Epoch 16 Batch 500 Loss 0.0839\n",
            "Epoch 16 Batch 600 Loss 0.0875\n",
            "Epoch 16 Loss 0.0613\n",
            "Time taken for 1 epoch 65.43128800392151 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.0352\n",
            "Epoch 17 Batch 100 Loss 0.0473\n",
            "Epoch 17 Batch 200 Loss 0.0546\n",
            "Epoch 17 Batch 300 Loss 0.0569\n",
            "Epoch 17 Batch 400 Loss 0.0304\n",
            "Epoch 17 Batch 500 Loss 0.0269\n",
            "Epoch 17 Batch 600 Loss 0.0654\n",
            "Epoch 17 Loss 0.0573\n",
            "Time taken for 1 epoch 65.4875762462616 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.0742\n",
            "Epoch 18 Batch 100 Loss 0.0445\n",
            "Epoch 18 Batch 200 Loss 0.0492\n",
            "Epoch 18 Batch 300 Loss 0.0668\n",
            "Epoch 18 Batch 400 Loss 0.0421\n",
            "Epoch 18 Batch 500 Loss 0.0322\n",
            "Epoch 18 Batch 600 Loss 0.0829\n",
            "Epoch 18 Loss 0.0560\n",
            "Time taken for 1 epoch 65.77809500694275 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.0682\n",
            "Epoch 19 Batch 100 Loss 0.0304\n",
            "Epoch 19 Batch 200 Loss 0.0385\n",
            "Epoch 19 Batch 300 Loss 0.0680\n",
            "Epoch 19 Batch 400 Loss 0.0708\n",
            "Epoch 19 Batch 500 Loss 0.0646\n",
            "Epoch 19 Batch 600 Loss 0.0548\n",
            "Epoch 19 Loss 0.0523\n",
            "Time taken for 1 epoch 65.62817239761353 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.0730\n",
            "Epoch 20 Batch 100 Loss 0.0502\n",
            "Epoch 20 Batch 200 Loss 0.0521\n",
            "Epoch 20 Batch 300 Loss 0.0486\n",
            "Epoch 20 Batch 400 Loss 0.0576\n",
            "Epoch 20 Batch 500 Loss 0.0712\n",
            "Epoch 20 Batch 600 Loss 0.0601\n",
            "Epoch 20 Loss 0.0503\n",
            "Time taken for 1 epoch 66.8307433128357 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsG41Cg1Sa-R",
        "colab_type": "text"
      },
      "source": [
        "### Evaluacion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TGt_9nMScZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def translate(sentence,flag=False):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "  if flag:\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n",
        "\n",
        "\n",
        "def delete_etiquetas(sentence):\n",
        "    sentence = sentence.replace(\"<start>\",\"\").replace(\"<end>\",\"\")\n",
        "    return sentence.strip()\n",
        "\n",
        "def translate2(sentence):\n",
        "    result, sentence,attention_plot = evaluate(sentence)\n",
        "    return delete_etiquetas(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuZytOU-SjUg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cb1f8a3b-75e4-422b-8759-fb065bc9a22a"
      },
      "source": [
        "#Restaurar el ultimo checkpoint\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f2e42947710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHkVydNjSmPx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9bdffa6b-47e0-4ba0-961e-a4db3ecd1e25"
      },
      "source": [
        "%%time\n",
        "esp = []\n",
        "pred_con_a = []\n",
        "\n",
        "total = len(input_tensor_val)\n",
        "procec = 0\n",
        "p_prog = 0.1\n",
        "\n",
        "for x,y in zip(input_tensor_val,target_tensor_val):\n",
        "    x = delete_etiquetas(convertir(inp_lang,x))\n",
        "    y = delete_etiquetas(convertir(targ_lang,y))\n",
        "    z = translate2(x)\n",
        "    esp.append(x)\n",
        "    pred_con_a.append(z)\n",
        "    if procec/total > p_prog:\n",
        "        print(\"Progreso de:\",int(100*p_prog),\"%\")\n",
        "        p_prog += 0.1\n",
        "\n",
        "#Lo reutilizamos de la parte anterior, pero es el final con ambos tipos\n",
        "DataSetSinAtencion[\"Prediccion Con A\"] = pred_con_a\n",
        "DataSetSinAtencion[\"Spanish\"] = esp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 8min 51s, sys: 27.2 s, total: 9min 18s\n",
            "Wall time: 9min 8s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ARtNaLwd28d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "8a5448ba-e13a-4a8a-d79a-bca2bd7ff923"
      },
      "source": [
        "DataSetSinAtencion.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prediccion Sin A</th>\n",
              "      <th>Real</th>\n",
              "      <th>Prediccion Con A</th>\n",
              "      <th>Spanish</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>this is our room .</td>\n",
              "      <td>this is your key .</td>\n",
              "      <td>this is your key .</td>\n",
              "      <td>esta es vuestra llave .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>he had a wife .</td>\n",
              "      <td>he had one daughter .</td>\n",
              "      <td>he had a daughter .</td>\n",
              "      <td>el tenia una hija .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>my s the is is true .</td>\n",
              "      <td>part of his story is true .</td>\n",
              "      <td>part of his story is true .</td>\n",
              "      <td>parte de su historia es cierta .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tom never never dumb .</td>\n",
              "      <td>tom never had doubts .</td>\n",
              "      <td>tom has never asked of doubts .</td>\n",
              "      <td>tomas nunca tuvo dudas .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>we ll nothing nothing .</td>\n",
              "      <td>we didn t learn anything .</td>\n",
              "      <td>we didn t have anything .</td>\n",
              "      <td>no aprendimos nada .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i need a to with now .</td>\n",
              "      <td>i need a place to live .</td>\n",
              "      <td>i need a place to live .</td>\n",
              "      <td>necesito un lugar para vivir .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>you can t be a joke .</td>\n",
              "      <td>you can t be a doctor .</td>\n",
              "      <td>you can t be a doctor .</td>\n",
              "      <td>no puedes ser medico .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>what s the name ?</td>\n",
              "      <td>what s your name ?</td>\n",
              "      <td>what s its name ?</td>\n",
              "      <td>¿ como se llama ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>i think in . .</td>\n",
              "      <td>i m thinking about you .</td>\n",
              "      <td>i think about you .</td>\n",
              "      <td>pienso en ustedes .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>what are your parents ?</td>\n",
              "      <td>what are your duties ?</td>\n",
              "      <td>what are your intentions ?</td>\n",
              "      <td>¿ cuales son sus funciones ?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Prediccion Sin A  ...                           Spanish\n",
              "0       this is our room .  ...           esta es vuestra llave .\n",
              "1          he had a wife .  ...               el tenia una hija .\n",
              "2    my s the is is true .  ...  parte de su historia es cierta .\n",
              "3   tom never never dumb .  ...          tomas nunca tuvo dudas .\n",
              "4  we ll nothing nothing .  ...              no aprendimos nada .\n",
              "5   i need a to with now .  ...    necesito un lugar para vivir .\n",
              "6    you can t be a joke .  ...            no puedes ser medico .\n",
              "7        what s the name ?  ...                 ¿ como se llama ?\n",
              "8           i think in . .  ...               pienso en ustedes .\n",
              "9  what are your parents ?  ...      ¿ cuales son sus funciones ?\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbXTZvYaS-O5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "abb334ed-53e5-4fee-a823-104476373309"
      },
      "source": [
        "print(\"Oraciones exactas predecidas Sin A:\",len(DataSetSinAtencion[DataSetSinAtencion['Prediccion Sin A'] == DataSetSinAtencion.Real]))\n",
        "print(\"Oraciones exactas predecidas Con A:\",len(DataSetSinAtencion[DataSetSinAtencion['Prediccion Con A'] == DataSetSinAtencion.Real]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Oraciones exactas predecidas Sin A: 592\n",
            "Oraciones exactas predecidas Con A: 2714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xinBuP2UeAhL",
        "colab_type": "text"
      },
      "source": [
        "Se puede ver que las predicciones utilizando la atención de Bahdanau son son mucho mejores. Se logra predecir un 25% de las oraciones esperadas. Aunque algunas oraciones distintas mantienen el mismo significado y pueden considerarse correctas. Un ejemplo es:\n",
        "\n",
        "Real: what's your name?\n",
        "Pred Con A: what's it's name? \n",
        "Español: ¿Cómo se llama?\n",
        "\n",
        "Dado el contexto de la oracion original tanto *your* como *it's* son pronombres válidos para el sujeto en esta oración. Habría que darle mas contexto a la oración."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yRcJdVienwJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "90ed5fb5-12f6-47c6-9aaa-5a6bccdeb956"
      },
      "source": [
        "print(translate2(u\"¿Cómo se llama?\"))\n",
        "print(translate2(u\"¿Cómo te llamas?\"))\n",
        "print(translate2(u\"¿Cómo te llamas tú?\"))\n",
        "print(translate2(u\"¿Cómo se llama eso?\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "what s its name ?\n",
            "what s your name ?\n",
            "what s your name ?\n",
            "what s it called ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0w1ppPmfT1K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "65fc6a1c-3b1d-48b4-83b0-0753cda4f611"
      },
      "source": [
        "translate(u\"¿Cómo se llama?\",flag=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> ¿ como se llama ? <end>\n",
            "Predicted translation: what s its name ? <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFAqihtofanx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "d1447205-4729-43a5-f51e-2999d430b6cd"
      },
      "source": [
        "translate(u\"¿Cómo te llamas?\",flag=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> ¿ como te llamas ? <end>\n",
            "Predicted translation: what s your name ? <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyhBo620fA9u",
        "colab_type": "text"
      },
      "source": [
        "Con estas pequeñas pruebas se puede ver que al utilizar *llama* o *llamas* cambia el gráfico de atención.\n",
        "\n",
        "Usualmente cuando nos referimos a una persona nosotros decimos ¿Cómo te llamas? y el ¿Cómo se llama? usualmente lo usamos en un contexto similar a: ¿Cómo se llama tu perro? y para animales el pronombre que se tiende a utilizar en inglés es *it*.\n",
        "\n",
        "En esta categoría gana la red con atención por lejos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3urm-tgNIQHO",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Real 2: Fragmento de MS-COCO\n",
        "\n",
        "# Descripción dataset\n",
        "\n",
        "Se utilizará un fragmento del dataset MS-COCO (Common Objects in COntext), correspondiente a 82000 imágenes de variada resolución junto a una o más descripciones (caption). Debido al tamaño del dataset y limitaciones de hardware, se usará un subconjunto de alrededor de 30000 muestras, donde cada una corresponde a una imágen y una única descripción."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xWWFyNTJpBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmnCLl3PIrLv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "1834bd81-cc9a-4d88-9e58-bd05d6331e3c"
      },
      "source": [
        "# Descarga descripciones\n",
        "annotation_folder = '/annotations/'\n",
        "if not os.path.exists(os.path.abspath('.') + annotation_folder):\n",
        "  annotation_zip = tf.keras.utils.get_file('captions.zip',\n",
        "                                          cache_subdir=os.path.abspath('.'),\n",
        "                                          origin = 'http://images.cocodataset.org/annotations/annotations_trainval2014.zip',\n",
        "                                          extract = True)\n",
        "  annotation_file = os.path.dirname(annotation_zip)+'/annotations/captions_train2014.json'\n",
        "  os.remove(annotation_zip)\n",
        "\n",
        "# Descarga imágenes. Advertencia: cerca de 13 GB\n",
        "image_folder = '/train2014/'\n",
        "if not os.path.exists(os.path.abspath('.') + image_folder):\n",
        "  image_zip = tf.keras.utils.get_file('train2014.zip',\n",
        "                                      cache_subdir=os.path.abspath('.'),\n",
        "                                      origin = 'http://images.cocodataset.org/zips/train2014.zip',\n",
        "                                      extract = True)\n",
        "  PATH = os.path.dirname(image_zip) + image_folder\n",
        "  os.remove(image_zip)\n",
        "else:\n",
        "  PATH = os.path.abspath('.') + image_folder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
            "252878848/252872794 [==============================] - 8s 0us/step\n",
            "Downloading data from http://images.cocodataset.org/zips/train2014.zip\n",
            "13510574080/13510573713 [==============================] - 408s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-2AykPQJAW1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "40821f98-383d-40f8-fc29-19678d2512ed"
      },
      "source": [
        "# Carga de descripciones\n",
        "with open(annotation_file, 'r') as f:\n",
        "    annotations = json.load(f)\n",
        "\n",
        "#generar listas corelativas de descripciones y path de imagen\n",
        "all_captions = []\n",
        "all_img_name_vector = []\n",
        "for annot in annotations['annotations']:\n",
        "    caption = '<start> ' + annot['caption'] + ' <end>'\n",
        "    image_id = annot['image_id']\n",
        "    full_coco_image_path = PATH + 'COCO_train2014_' + '%012d.jpg' % (image_id)\n",
        "\n",
        "    all_img_name_vector.append(full_coco_image_path)\n",
        "    all_captions.append(caption)\n",
        "\n",
        "# Se realiza shuffle a las listas y se eligen 30k elementos\n",
        "train_captions, img_name_vector = shuffle(all_captions,\n",
        "                                          all_img_name_vector,\n",
        "                                          random_state=1)\n",
        "\n",
        "num_examples = 30000\n",
        "train_captions = train_captions[:num_examples]\n",
        "img_name_vector = img_name_vector[:num_examples]\n",
        "len(train_captions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kusxpen0KHlZ",
        "colab_type": "text"
      },
      "source": [
        "## Preprocesamiento\n",
        "\n",
        "El preprocesamiento de imágenes consta de reescalar cada imagen a una resolución de 299px*299px, además de escalar sus canales RGB para que se encuentren dentro del rango [-1, 1] para facilitar el cálculo de buenos pesos dentro de las redes a trabajar.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bkPM2--M7v6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image(image_path):\n",
        "    #Abrir imágen\n",
        "    img = tf.io.read_file(image_path)\n",
        "    #Leer sus 3 canales RGB\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    #Reescalar\n",
        "    img = tf.image.resize(img, (299, 299))\n",
        "    #Cambiar rango de los canales de pixeles.\n",
        "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "    return img, image_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXhJR2u-NO0K",
        "colab_type": "text"
      },
      "source": [
        "Posteriormente se empleará la red InceptionV3 entrenada con imagenet, la cual entregará descriptores de características de la imágen del dataset. Para ahorrar espacio en disco, se guardarán los descriptores resultantes en disco."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D94Y7jtRNor2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "be7e8122-039e-4e98-a41f-1389317536d8"
      },
      "source": [
        "#Obtenemos la red pre-entrenada\n",
        "image_model = tf.keras.applications.InceptionV3(include_top=False,\n",
        "                                                weights='imagenet')\n",
        "#Y la clonamos para nuestra red\n",
        "new_input = image_model.input\n",
        "hidden_layer = image_model.layers[-1].output\n",
        "image_features_extract_model = tf.keras.Model(new_input, hidden_layer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvvK30bvNw6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Eliminamos posibles nombres de archivos duplicados\n",
        "encode_train = sorted(set(img_name_vector))\n",
        "\n",
        "# Preparamos dataset cargando imagenes en batches, para evitar un overflow de \n",
        "# ram\n",
        "image_dataset = tf.data.Dataset.from_tensor_slices(encode_train)\n",
        "image_dataset = image_dataset.map(\n",
        "  load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(16)\n",
        "\n",
        "# Calculamos los features y los guardamos automaticamente en disco. Usaremos ese \n",
        "# archivo a futuro como nuestro input\n",
        "for img, path in image_dataset:\n",
        "  batch_features = image_features_extract_model(img)\n",
        "  batch_features = tf.reshape(batch_features,\n",
        "                              (batch_features.shape[0], -1, batch_features.shape[3]))\n",
        "\n",
        "  for bf, p in zip(batch_features, path):\n",
        "    path_of_feature = p.numpy().decode(\"utf-8\")\n",
        "    np.save(path_of_feature, bf.numpy())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P8dpHDOO2FJ",
        "colab_type": "text"
      },
      "source": [
        "A continuación, se generarán tokens del universo de palabras de las descripciones a trabajar. Para evitar problemas de memoria, se trabajará con un máximo de 5000 palabras, reemplazando las palabras excluidas por el token \"UNK\". Además, se necesita estandarizar el tamaño de las secuencias de las descripciones, requiriendo realizar padding con un token en específico, \"PAD\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XndvK5PwPP6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calcula el tamano de la descripcion mas larga\n",
        "def calc_max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8rUBNZfPSYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenizamos con maximo de 5k palabras\n",
        "top_k = 5000\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=top_k,\n",
        "                                                  oov_token=\"<unk>\",\n",
        "                                                  filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
        "# Calculamos los tokens de las descripciones\n",
        "tokenizer.fit_on_texts(train_captions)\n",
        "train_seqs = tokenizer.texts_to_sequences(train_captions)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUYUhx2APUOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Agregamos el token de padding\n",
        "tokenizer.word_index['<pad>'] = 0\n",
        "tokenizer.index_word[0] = '<pad>'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Alina7kEPWE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Recalculamos los tokens junto el pad token\n",
        "train_seqs = tokenizer.texts_to_sequences(train_captions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-ewqZ66Paau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#aplicamos el padding\n",
        "cap_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, padding='post')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvrz8CmWPa6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Almacenaos el largo maximo, para mas adelante\n",
        "max_length = calc_max_length(train_seqs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiCV6cmCQoFB",
        "colab_type": "text"
      },
      "source": [
        "Inicialmente se decidió emplear un split para validación, pero no fue usado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhhOPYLtQnik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split 80/20\n",
        "img_name_train, img_name_val, cap_train, cap_val = train_test_split(img_name_vector,\n",
        "                                                                    cap_vector,\n",
        "                                                                    test_size=0.2,\n",
        "                                                                    random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BcAuerYQy28",
        "colab_type": "text"
      },
      "source": [
        "## Modelo\n",
        "\n",
        "El modelo consiste en una arqitectura encoder-decoder. Como se empleó el uso de InceptionV3 para codificar la imagen en features, se considerará este como parte del encoder. La última parte del encoder corresponde a una capa densa,a activada con ReLU, que tomará dichos descriptores para formar la secuencia que recibirá la siguiente parte del modelo. \n",
        "\n",
        "Para el decoder, se construye usando una red GRU de 512 unidades con 2 capas densas que se encargarán de, por cada espacio de la secuencia de salida, definir el token correspondiente en dicha posición. Se tendrá una version del decoder que implemente atención de Bahdanau, , activada con Relu, y otra sin aplicar dicha atención."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqSJhl7UQygL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configuracion para trabajar inputs desde disco.\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "# Codificamos features\n",
        "embedding_dim = 256\n",
        "units = 512\n",
        "vocab_size = top_k + 1\n",
        "num_steps = len(img_name_train) // BATCH_SIZE\n",
        "# Features generadas forman vector de 64*2048\n",
        "features_shape = 2048\n",
        "attention_features_shape = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2wH2JNsRLaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# carga archivo de features desde disco\n",
        "def map_func(img_name, cap):\n",
        "  img_tensor = np.load(img_name.decode('utf-8')+'.npy')\n",
        "  return img_tensor, cap\n",
        "\n",
        "#Preparamos dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((img_name_train, cap_train))\n",
        "\n",
        "# Carga de archivos por batches\n",
        "dataset = dataset.map(lambda item1, item2: tf.numpy_function(\n",
        "          map_func, [item1, item2], [tf.float32, tf.int32]),\n",
        "          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# Shuffle\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOxbS7CaT4YE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Capas\n",
        "\n",
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, features, hidden):\n",
        "    hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "    score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
        "    attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
        "    context_vector = attention_weights * features\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "    return context_vector, attention_weights\n",
        "  \n",
        "class CNN_Encoder(tf.keras.Model):\n",
        "  def __init__(self, embedding_dim):\n",
        "      super(CNN_Encoder, self).__init__()\n",
        "      # de las 2048 features, las codificamos en 256 elementos\n",
        "      self.fc = tf.keras.layers.Dense(embedding_dim)\n",
        "  def call(self, x):\n",
        "      x = self.fc(x)\n",
        "      x = tf.nn.relu(x)\n",
        "      return x\n",
        "\n",
        "class RNN_Decoder(tf.keras.Model):\n",
        "  def __init__(self, embedding_dim, units, vocab_size):\n",
        "    super(RNN_Decoder, self).__init__()\n",
        "    self.units = units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc1 = tf.keras.layers.Dense(self.units)\n",
        "    self.fc2 = tf.keras.layers.Dense(vocab_size)\n",
        "    self.attention = BahdanauAttention(self.units)\n",
        "\n",
        "  def call(self, x, features, hidden):\n",
        "    # calculamos atencion\n",
        "    context_vector, attention_weights = self.attention(features, hidden)\n",
        "    x = self.embedding(x)\n",
        "    # Agregamos atencion para que GRU lo emplee\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "    output, state = self.gru(x)\n",
        "    x = self.fc1(output)\n",
        "    x = tf.reshape(x, (-1, x.shape[2]))\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x, state, attention_weights\n",
        "  def reset_state(self, batch_size):\n",
        "    return tf.zeros((batch_size, self.units))\n",
        "\n",
        "\n",
        "class RNN_Decoder_NA(tf.keras.Model):\n",
        "  #mismo decoder, sin usar atencion\n",
        "  def __init__(self, embedding_dim, units, vocab_size):\n",
        "    super(RNN_Decoder_NA, self).__init__()\n",
        "    self.units = units\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc1 = tf.keras.layers.Dense(self.units)\n",
        "    self.fc2 = tf.keras.layers.Dense(vocab_size)\n",
        "  def call(self, x, features, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x)\n",
        "    x = self.fc1(output)\n",
        "    x = tf.reshape(x, (-1, x.shape[2]))\n",
        "    x = self.fc2(x)\n",
        "    return x, state\n",
        "\n",
        "  def reset_state(self, batch_size):\n",
        "    return tf.zeros((batch_size, self.units))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmIQQYDfVJJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = CNN_Encoder(embedding_dim)\n",
        "decoder = RNN_Decoder(embedding_dim, units, vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR2X03XyVKM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creamos otro encoder, para que entrene sus propios pesos\n",
        "encoder_NA = CNN_Encoder(embedding_dim)\n",
        "decoder_NA = RNN_Decoder_NA(embedding_dim, units, vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgxCVlCRVQff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7c-shXfVTwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Checkpoints por si colab me kickeaba\n",
        "checkpoint_path = \"./checkpoints/train\"\n",
        "ckpt = tf.train.Checkpoint(encoder=encoder,\n",
        "                           decoder=decoder,\n",
        "                           optimizer = optimizer)\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "start_epoch = 0\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n",
        "  # restoring the latest checkpoint in checkpoint_path\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk1pt6rKVY_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"./checkpoints/train_NA\"\n",
        "ckpt_NA = tf.train.Checkpoint(encoder=encoder_NA,\n",
        "                           decoder=decoder_NA,\n",
        "                           optimizer = optimizer)\n",
        "ckpt_manager_NA = tf.train.CheckpointManager(ckpt_NA, checkpoint_path, max_to_keep=5)\n",
        "start_epoch_NA = 0\n",
        "if ckpt_manager_NA.latest_checkpoint:\n",
        "  start_epoch_NA = int(ckpt_manager_NA.latest_checkpoint.split('-')[-1])\n",
        "  # restoring the latest checkpoint in checkpoint_path\n",
        "  ckpt_NA.restore(ckpt_manager_NA.latest_checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70PN0m_mVbdT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bdeb214a-f78f-4847-8fa0-df37ce474c41"
      },
      "source": [
        "start_epoch, start_epoch_NA"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tpeGXBsVc-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_plot = []\n",
        "loss_plot_NA = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voA92nfKVf_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(img_tensor, target):\n",
        "  loss = 0\n",
        "  hidden = decoder.reset_state(batch_size=target.shape[0])\n",
        "  dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * target.shape[0], 1)\n",
        "  with tf.GradientTape() as tape:\n",
        "      features = encoder(img_tensor)\n",
        "\n",
        "      for i in range(1, target.shape[1]):\n",
        "          predictions, hidden, _ = decoder(dec_input, features, hidden)\n",
        "          loss += loss_function(target[:, i], predictions)\n",
        "          dec_input = tf.expand_dims(target[:, i], 1)\n",
        "\n",
        "  total_loss = (loss / int(target.shape[1]))\n",
        "  trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "  return loss, total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev-c8wHGVmaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step_NA(img_tensor, target):\n",
        "  loss = 0\n",
        "  hidden = decoder_NA.reset_state(batch_size=target.shape[0])\n",
        "  dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * target.shape[0], 1)\n",
        "  with tf.GradientTape() as tape:\n",
        "      features = encoder(img_tensor)\n",
        "      for i in range(1, target.shape[1]):\n",
        "          predictions, hidden = decoder_NA(dec_input, features, hidden)\n",
        "          loss += loss_function(target[:, i], predictions)\n",
        "          dec_input = tf.expand_dims(target[:, i], 1)\n",
        "  total_loss = (loss / int(target.shape[1]))\n",
        "  trainable_variables = encoder.trainable_variables + decoder_NA.trainable_variables\n",
        "  gradients = tape.gradient(loss, trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "  return loss, total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z6Xr_9cVwXl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "a5a11fce-1a54-4c6c-bbbf-7308d33aa200"
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(start_epoch, EPOCHS):\n",
        "    start = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (img_tensor, target)) in enumerate(dataset):\n",
        "        batch_loss, t_loss = train_step(img_tensor, target)\n",
        "        total_loss += t_loss\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print ('Epoch {} Batch {} Loss {:.4f}'.format(\n",
        "              epoch + 1, batch, batch_loss.numpy() / int(target.shape[1])))\n",
        "    # storing the epoch end loss value to plot later\n",
        "    loss_plot.append(total_loss / num_steps)\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "      ckpt_manager.save()\n",
        "\n",
        "    print ('Epoch {} Loss {:.6f}'.format(epoch + 1,\n",
        "                                         total_loss/num_steps))\n",
        "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.0257\n",
            "Epoch 1 Batch 100 Loss 1.1362\n",
            "Epoch 1 Batch 200 Loss 1.0297\n",
            "Epoch 1 Batch 300 Loss 0.9011\n",
            "Epoch 1 Loss 1.052403\n",
            "Time taken for 1 epoch 383.4037501811981 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.8726\n",
            "Epoch 2 Batch 100 Loss 0.8020\n",
            "Epoch 2 Batch 200 Loss 0.7910\n",
            "Epoch 2 Batch 300 Loss 0.6997\n",
            "Epoch 2 Loss 0.798373\n",
            "Time taken for 1 epoch 362.0157446861267 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.7272\n",
            "Epoch 3 Batch 100 Loss 0.6945\n",
            "Epoch 3 Batch 200 Loss 0.6822\n",
            "Epoch 3 Batch 300 Loss 0.7520\n",
            "Epoch 3 Loss 0.727064\n",
            "Time taken for 1 epoch 359.4869544506073 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.6750\n",
            "Epoch 4 Batch 100 Loss 0.7280\n",
            "Epoch 4 Batch 200 Loss 0.6766\n",
            "Epoch 4 Batch 300 Loss 0.6810\n",
            "Epoch 4 Loss 0.681234\n",
            "Time taken for 1 epoch 357.5445098876953 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.6750\n",
            "Epoch 5 Batch 100 Loss 0.6672\n",
            "Epoch 5 Batch 200 Loss 0.6398\n",
            "Epoch 5 Batch 300 Loss 0.6275\n",
            "Epoch 5 Loss 0.645611\n",
            "Time taken for 1 epoch 357.97180938720703 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6m1SwLbVxuB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "0e077077-0549-402d-bfca-48a169397379"
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(start_epoch_NA, EPOCHS):\n",
        "    start = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (img_tensor, target)) in enumerate(dataset):\n",
        "        batch_loss, t_loss = train_step_NA(img_tensor, target)\n",
        "        total_loss += t_loss\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print ('Epoch {} Batch {} Loss {:.4f}'.format(\n",
        "              epoch + 1, batch, batch_loss.numpy() / int(target.shape[1])))\n",
        "    # storing the epoch end loss value to plot later\n",
        "    loss_plot_NA.append(total_loss / num_steps)\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "      ckpt_manager_NA.save()\n",
        "\n",
        "    print ('Epoch {} Loss {:.6f}'.format(epoch + 1,\n",
        "                                         total_loss/num_steps))\n",
        "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['cnn__encoder/dense/kernel:0', 'cnn__encoder/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['cnn__encoder/dense/kernel:0', 'cnn__encoder/dense/bias:0'] when minimizing the loss.\n",
            "Epoch 1 Batch 0 Loss 1.9474\n",
            "Epoch 1 Batch 100 Loss 0.9651\n",
            "Epoch 1 Batch 200 Loss 0.9631\n",
            "Epoch 1 Batch 300 Loss 1.0108\n",
            "Epoch 1 Loss 1.013240\n",
            "Time taken for 1 epoch 373.6913561820984 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.9724\n",
            "Epoch 2 Batch 100 Loss 0.9141\n",
            "Epoch 2 Batch 200 Loss 0.8531\n",
            "Epoch 2 Batch 300 Loss 0.9224\n",
            "Epoch 2 Loss 0.899787\n",
            "Time taken for 1 epoch 363.1179313659668 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.8438\n",
            "Epoch 3 Batch 100 Loss 0.8552\n",
            "Epoch 3 Batch 200 Loss 0.8427\n",
            "Epoch 3 Batch 300 Loss 0.8949\n",
            "Epoch 3 Loss 0.870999\n",
            "Time taken for 1 epoch 365.3070366382599 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.8648\n",
            "Epoch 4 Batch 100 Loss 0.8894\n",
            "Epoch 4 Batch 200 Loss 0.8636\n",
            "Epoch 4 Batch 300 Loss 0.8404\n",
            "Epoch 4 Loss 0.853326\n",
            "Time taken for 1 epoch 363.28822922706604 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.8073\n",
            "Epoch 5 Batch 100 Loss 0.8838\n",
            "Epoch 5 Batch 200 Loss 0.8706\n",
            "Epoch 5 Batch 300 Loss 0.8699\n",
            "Epoch 5 Loss 0.841006\n",
            "Time taken for 1 epoch 362.423641204834 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjaifLdxV3_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(image):\n",
        "    hidden = decoder.reset_state(batch_size=1)\n",
        "    temp_input = tf.expand_dims(load_image(image)[0], 0)\n",
        "    img_tensor_val = image_features_extract_model(temp_input)\n",
        "    img_tensor_val = tf.reshape(img_tensor_val, (img_tensor_val.shape[0], -1, img_tensor_val.shape[3]))\n",
        "    features = encoder(img_tensor_val)\n",
        "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
        "    result = []\n",
        "    for i in range(max_length):\n",
        "        predictions, hidden, _ = decoder(dec_input, features, hidden)\n",
        "        predicted_id = tf.random.categorical(predictions, 1)[0][0].numpy()\n",
        "        result.append(tokenizer.index_word[predicted_id])\n",
        "        if tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0pibTheV6nO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_NA(image):\n",
        "    hidden = decoder_NA.reset_state(batch_size=1)\n",
        "    temp_input = tf.expand_dims(load_image(image)[0], 0)\n",
        "    img_tensor_val = image_features_extract_model(temp_input)\n",
        "    img_tensor_val = tf.reshape(img_tensor_val, (img_tensor_val.shape[0], -1, img_tensor_val.shape[3]))\n",
        "    features = encoder_NA(img_tensor_val)\n",
        "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
        "    result = []\n",
        "    for i in range(max_length):\n",
        "        predictions, hidden = decoder_NA(dec_input, features, hidden)\n",
        "        predicted_id = tf.random.categorical(predictions, 1)[0][0].numpy()\n",
        "        result.append(tokenizer.index_word[predicted_id])\n",
        "        if tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drBLgJ9eWXxx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "28aa395c-721c-4265-da66-a1034b87f44c"
      },
      "source": [
        "plt.plot(loss_plot_NA)\n",
        "plt.plot(loss_plot)\n",
        "plt.legend([\"Sin Atencion\", \"Con Atencion\"])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Plot')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bssK9vIoWlEg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "48c7327c-8354-41b1-c974-a2fbe48e83a1"
      },
      "source": [
        "rid = np.random.randint(0, len(img_name_val))\n",
        "image = img_name_val[rid]\n",
        "real_caption = ' '.join([tokenizer.index_word[i] for i in cap_val[rid] if i not in [0]])\n",
        "result = evaluate(image)\n",
        "result_NA = evaluate_NA(image)\n",
        "print ('Desc. Real:', real_caption)\n",
        "print ('Pred. Desc:', ' '.join(result))\n",
        "print ('Pred Desc sin Atencion:', ' '.join(result_NA))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Desc. Real: <start> bowl of pork and beans and cup in front of a toaster <end>\n",
            "Pred. Desc: the silver pot on top and feeds their wall <end>\n",
            "Pred Desc sin Atencion: pictures of bananas inside an empty table <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mro0DvciPO8t",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#Challenge Kaggle\n",
        "\n",
        "El objetivo del challenge es asignar labels a los tweets relacionados a si son falsos o verdaderos. Primero se hará una análisis general del dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no4BhCKje0PD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1jWuQ6LROlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "training_labels = pd.read_csv(\"/content/drive/My Drive/ANNT2/Challenge/train_labels.csv\")\n",
        "n_rows = len(training_labels)\n",
        "\n",
        "for lab in training_labels[\"label\"].unique():\n",
        "    total = len(training_labels[training_labels.label == lab])\n",
        "    porcentaje = round(total/n_rows,3)\n",
        "    print(lab,\"Frec:\",total,\"Frec R:\",porcentaje)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dig9hr-LRWmm",
        "colab_type": "text"
      },
      "source": [
        "En el dataset se aprecia un leve desbalanceo de clases. La clase unverified es la que tiene una frecuencia muy distinta en relación a las otras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX0-Y-ZCRS9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Ahora vamos por el texto:\n",
        "\n",
        "id = []\n",
        "content = []\n",
        "label = []\n",
        "for_test = []\n",
        "\n",
        "train_tweet_text = open(\"/content/drive/My Drive/ANNT2/Challenge/train_source_tweets.txt\",\"rt\")\n",
        "for linea in train_tweet_text:\n",
        "    t_id,t_content = linea.strip().split(\"\\t\")\n",
        "    id.append(int(t_id))\n",
        "    content.append(t_content)\n",
        "    for_test.append(\"no\")\n",
        "\n",
        "train_tweet_text.close()\n",
        "#Hay que hacer un merge con los labels\n",
        "for x in id:\n",
        "    df = training_labels[training_labels[\"id\"]==x]\n",
        "    l = df[\"label\"].values[0]\n",
        "    label.append(l)\n",
        "\n",
        "#Creamos el dataset\n",
        "diccio = {\"id\":id,\"content\":content,\"label\":label,\"test\":for_test}\n",
        "training_dataset = pd.DataFrame.from_dict(diccio)\n",
        "print(training_dataset.head())\n",
        "\n",
        "\n",
        "test_path = \"/content/drive/My Drive/ANNT2/Challenge/test_source_tweets.txt\"\n",
        "\n",
        "test_id = []\n",
        "test_content = []\n",
        "for_test = []\n",
        "label = []\n",
        "\n",
        "archivo = open(test_path,\"rt\",encoding=\"utf-8\")\n",
        "for linea in archivo:\n",
        "    tid,t_content = linea.strip().split(\"\\t\")\n",
        "    test_id.append(int(tid))\n",
        "    test_content.append(t_content)\n",
        "    for_test.append(\"si\")\n",
        "    label.append(\"dumb_label\")\n",
        "\n",
        "archivo.close()\n",
        "diccio = {\"id\":test_id,\"content\":test_content,\"label\":label,\"test\":for_test}\n",
        "\n",
        "test_dataset = pd.DataFrame.from_dict(diccio)\n",
        "test_dataset.sort_values(by=[\"id\"],inplace=True,ascending=True)\n",
        "print(test_dataset.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBcS_EEcReaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_dataset = training_dataset.append(test_dataset,ignore_index=True)\n",
        "print(len(training_dataset))\n",
        "\n",
        "contador = 0\n",
        "for sentence in training_dataset[\"content\"]:\n",
        "    if \"url\" in sentence.lower():\n",
        "        contador += 1\n",
        "    \n",
        "print(\"Url en \",contador,\"tweets. De un total de:\",len(training_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPixbnHDRhJ6",
        "colab_type": "text"
      },
      "source": [
        "## Preprocesamiento\n",
        "\n",
        "Se creará una nueva columna con los tweets sin stopwords y se van a predecir las etiquetas utilizando una RNN. Además se utilizará un modelo multi-input para trabajar con características extraídas del grafo. Leyendo las oraciones, aparece mucho la palabra \"url\" en todos los tweets así que se agrega a la lista de stopwords."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SVKLi7wRjjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "all_stopwords = nltk.corpus.stopwords.words('english')\n",
        "all_stopwords.append(\"url\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx1K1xEkRnta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_sw(dataset,column,sw):\n",
        "    without_sw = []\n",
        "    for x in dataset[column]:\n",
        "        x = x.lower()\n",
        "        x_tokenized = word_tokenize(x)\n",
        "        x_withoutsw = [w for w in x_tokenized if w not in sw ]\n",
        "        x_withoutsw = \" \".join(x_withoutsw)\n",
        "        without_sw.append(x_withoutsw)\n",
        "    return without_sw\n",
        "\n",
        "without_sw = remove_sw(training_dataset,\"content\",all_stopwords)\n",
        "training_dataset[\"content2\"] = without_sw\n",
        "training_dataset[[\"content\",\"content2\"]].head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3n0sMGARsEY",
        "colab_type": "text"
      },
      "source": [
        "Ahora se pasará el texto a una secuencia de tokens, de la misma forma que se hizo para el Dataset Real 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8igftaACRrDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "\n",
        "\n",
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "  \n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KNZ6xgaRxV7",
        "colab_type": "text"
      },
      "source": [
        "## Trabajo con el Grafo\n",
        "\n",
        "En el grafo de cada tweet se tiene lo siguiente:\n",
        "\n",
        "1. La primera linea indica al padre (tweet original)\n",
        "\n",
        "2. Las siguientes líneas son distintos retweets\n",
        "\n",
        "3. Los formatos son ['user_id', 'tweet_id', 'delay(min)']\n",
        "\n",
        "Utilizaremos las \"id\" en el dataset de entrenamiento original para obtener los atributos de los grafos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjXZAvkuR1Hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from statistics import median as mediana\n",
        "\n",
        "def is_father(diccio,node):\n",
        "    return node in diccio.keys()\n",
        "\n",
        "def max_depth(tree,origin_id,act_depth,visits):\n",
        "    max_depth_found = act_depth\n",
        "    for child in tree[origin_id]:\n",
        "        if child not in visits and is_father(tree,child):\n",
        "            visits.append(child)\n",
        "            new_depth = max_depth(tree,child,act_depth+1,visits)\n",
        "            if new_depth > max_depth_found:\n",
        "                max_depth_found = new_depth\n",
        "    return max_depth_found\n",
        "\n",
        "def media(lista):\n",
        "    suma = 0\n",
        "    for x in lista:\n",
        "        suma += x\n",
        "    return suma/len(lista)\n",
        "\n",
        "def analyze_graph(path,row_index):\n",
        "    offset = 0\n",
        "    graph = open(path,\"r\")\n",
        "    different_users = set()\n",
        "    father_dict = {}\n",
        "    delays = []\n",
        "    retweets = 0\n",
        "\n",
        "    for linea in graph:\n",
        "        linea = linea.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\")\n",
        "        linea = linea.strip().split(\"->\")\n",
        "        padre = linea[0].split(\",\")\n",
        "        hijo = linea[1].split(\",\")\n",
        "\n",
        "        if padre[0] == 'ROOT':\n",
        "            origin_id = int(hijo[0])\n",
        "            if origin_id not in father_dict.keys():\n",
        "                father_dict[origin_id] = set()\n",
        "            offset = float(hijo[2])\n",
        "            continue\n",
        "\n",
        "        retweets += 1\n",
        "\n",
        "        father = int(padre[0])\n",
        "        delay_father = float(padre[2])\n",
        "\n",
        "        son = int(hijo[0])\n",
        "        delay_son = float(hijo[2])\n",
        "\n",
        "        if father not in father_dict.keys():\n",
        "            father_dict[father] = set()\n",
        "            father_dict[father].add(son)\n",
        "        else:\n",
        "            father_dict[father].add(son)\n",
        "        \n",
        "\n",
        "\n",
        "        delays.append((delay_father,delay_son))\n",
        "        different_users.add(father)\n",
        "        different_users.add(son)\n",
        "\n",
        "    graph.close()\n",
        "\n",
        "    original_reach = len(father_dict[origin_id])\n",
        "    depth = max_depth(father_dict,origin_id,1,[origin_id])\n",
        "    dif_users = len(different_users)\n",
        "    delays = [(x-offset) + (y-offset) for x,y in delays]\n",
        "    max_delay = max(delays)\n",
        "    min_delay = min(delays)\n",
        "    mean_delay = media(delays)\n",
        "    percentaje_init = original_reach/dif_users\n",
        "    median_delay = mediana(delays)\n",
        "    varianza_delay = np.var(delays)\n",
        "    return original_reach,depth,dif_users,min_delay,mean_delay,max_delay,percentaje_init,median_delay,varianza_delay\n",
        "\n",
        "graph_path_train = \"/content/drive/My Drive/ANNT2/Challenge/train\"\n",
        "graph_path_test = \"/content/drive/My Drive/ANNT2/Challenge/test\"\n",
        "\n",
        "ori_reach = []\n",
        "tweet_depth = []\n",
        "dif_users = []\n",
        "min_delay = []\n",
        "mean_delay = []\n",
        "max_delay = []\n",
        "percent_reach = []\n",
        "median_delay = []\n",
        "variance_delay = [ ]\n",
        "analyzed = 0\n",
        "total = len(training_dataset)\n",
        "umbral = 0.1\n",
        "\n",
        "for i,row in training_dataset.iterrows():\n",
        "    dummyid = row['id']\n",
        "    for_testing = row['test']\n",
        "    if for_testing == \"no\":\n",
        "        g_path = graph_path_train+\"/\"+str(dummyid)+\".txt\"\n",
        "    else:\n",
        "        g_path = graph_path_test+\"/\"+str(dummyid)+\".txt\"\n",
        "    \n",
        "    o_r,de,users,midel,meandel,maxdel,per_rea,mediana_delay,varianza_delay = analyze_graph(g_path,dummyid)\n",
        "\n",
        "    ori_reach.append(o_r)\n",
        "    tweet_depth.append(de)\n",
        "    dif_users.append(users)\n",
        "    min_delay.append(midel)\n",
        "    mean_delay.append(meandel)\n",
        "    max_delay.append(maxdel)\n",
        "    percent_reach.append(per_rea)\n",
        "    median_delay.append(mediana_delay)\n",
        "    variance_delay.append(varianza_delay)\n",
        "    analyzed += 1\n",
        "    if analyzed/total > umbral:\n",
        "        print(umbral,\"%\")\n",
        "        umbral += 0.1\n",
        "\n",
        "\n",
        "training_dataset[\"ori_reach\"] = ori_reach \n",
        "training_dataset[\"depth\"] = tweet_depth \n",
        "training_dataset[\"users_reached\"] = dif_users \n",
        "training_dataset[\"min_delay\"] = min_delay \n",
        "training_dataset[\"mean_delay\"] = mean_delay \n",
        "training_dataset[\"max_delay\"] = max_delay\n",
        "training_dataset[\"mediana_delay\"] = median_delay\n",
        "training_dataset[\"variance_delay\"] = variance_delay\n",
        "training_dataset[\"percent_reach\"] = percent_reach "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1t50bARR38p",
        "colab_type": "text"
      },
      "source": [
        "Ahora tenemos un dataset con los textos y los datos del grafo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vn0POfcR4tn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_dataset.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LszUN0MkR7ST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def get_challenge_indexes(dataset,column,target):\n",
        "    index = 0\n",
        "    for value in dataset[column]:\n",
        "        if value == target:\n",
        "            return index\n",
        "        index +=1\n",
        "    return -1\n",
        "\n",
        "challenge = get_challenge_indexes(training_dataset,\"test\",\"si\") #index para separar el challenge\n",
        "graph_attributes = training_dataset[['mean_delay','mediana_delay',\n",
        "                                     'variance_delay','percent_reach','users_reached']]\n",
        "graph_data = graph_attributes.values\n",
        "graph_data_challenge = graph_data[challenge:]\n",
        "graph_data_train = graph_data[:challenge]\n",
        "\n",
        "#Ahora hacemos un escalado de los datos del grafico al intervalo [0,1] pero solo los de entrenamiento\n",
        "scaler = MinMaxScaler()\n",
        "numeric_train = scaler.fit_transform(graph_data_train)\n",
        "numeric_challenge = scaler.transform(graph_data_challenge) #ahora lo dejamos asi hasta terminar con el modelo\n",
        "print(numeric_train.shape,numeric_challenge.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbIqvsTyR_Wq",
        "colab_type": "text"
      },
      "source": [
        "## Trabajo con el Texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mW6jGT9SAM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "content_preproc = [preprocess_sentence(x) for x in training_dataset[\"content2\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijS7eqLeSD9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer\n",
        "\n",
        "def traducir(input,tokenizer):\n",
        "    sentence = \"\"\n",
        "    for token in input:\n",
        "        if token != 0:\n",
        "            sentence += tokenizer.index_word[token] + \" \"\n",
        "    return sentence\n",
        "\n",
        "input, tok_inp = tokenize(content_preproc) \n",
        "\n",
        "vocab_size = len(tok_inp.word_index)+1\n",
        "max_length = input.shape[1]\n",
        "print(input.shape)\n",
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_iJnnwwSGyh",
        "colab_type": "text"
      },
      "source": [
        "Ahora hay que volver a separar los datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcqMD6EHSIlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "challenge_input_text = input[challenge:] #aqui queda el challenge\n",
        "input_text = input[:challenge] #sacamos el challenge, solo queda el train\n",
        "y = training_dataset[\"label\"].to_numpy().reshape(-1,1)\n",
        "y = y[:challenge]\n",
        "\n",
        "print(input_text.shape,y.shape,challenge_input_text.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXukFPaCSK6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder as OneHot\n",
        "from sklearn.model_selection import train_test_split as tt_split\n",
        "encoder = OneHot(sparse=False)\n",
        "encoder.fit(y)\n",
        "encoded_Y = encoder.transform(y)\n",
        "decoded_Y = encoder.inverse_transform(encoded_Y)\n",
        "print(encoded_Y[0],decoded_Y[0])\n",
        "print(encoder.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YYMkLDeSPtH",
        "colab_type": "text"
      },
      "source": [
        "Ahora se crean los conjuntos de entrenamiento y de validacion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSkJ0NYLSNV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_trainX,num_testX, text_trainX,text_testX, y_train, y_test = tt_split(numeric_train,input_text,encoded_Y, test_size=0.2,random_state=0)\n",
        "\n",
        "print(\"Conjuntos\")\n",
        "print(\"Datos Grafo:\",num_trainX.shape,num_testX.shape)\n",
        "print(\"Datos Texto:\",text_trainX.shape,text_testX.shape)\n",
        "print(\"Y:\",y_train.shape,y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiH0nAhHSS5Z",
        "colab_type": "text"
      },
      "source": [
        "## Modelo\n",
        "\n",
        "Para el modelo se probará con una simple RNN con celdas GRU para el input del texto y para los datos del grafo se trabajará con capas densas. \n",
        "\n",
        "Después se concatenaran los dos modelos y se harán las predicciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swYQgLu1SSVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, GRU, Input \n",
        "from tensorflow.keras.layers import concatenate, Attention, AdditiveAttention, Conv1D, GlobalAveragePooling2D\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_path = \"/content/drive/My Drive/ANNT2/checkpoints\"\n",
        "\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_acc',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "\n",
        "#Modelo para el texto\n",
        "inputs_texto = Input(shape=(max_length,))\n",
        "texto_embedding = Embedding(vocab_size,32)(inputs_texto)\n",
        "texto_features = AdditiveAttention()([texto_embedding,texto_embedding])\n",
        "texto_features = LSTM(50)(texto_features)\n",
        "\n",
        "modelo_texto = Model(inputs = inputs_texto,outputs=texto_features)\n",
        "\n",
        "\n",
        "#Modelo para el grafo\n",
        "inputs_grafo = Input(shape=(num_trainX.shape[1],))\n",
        "grafo_features = Dense(50,activation='relu')(inputs_grafo)\n",
        "grafo_features = Dense(50,activation='relu')(grafo_features)\n",
        "grafo_features = Dense(25,activation='relu')(grafo_features)\n",
        "grafo_features = Dropout(0.2)(grafo_features)\n",
        "modelo_grafo = Model(inputs = inputs_grafo,outputs = grafo_features)\n",
        "\n",
        "combined = concatenate([modelo_texto.output,modelo_grafo.output])\n",
        "\n",
        "modelo_combinado = Dense(4,activation='softmax')(combined)\n",
        "#modelo_combinado = Dense(4,activation='softmax')(modelo_combinado)\n",
        "\n",
        "modelo_final = Model(inputs=[modelo_texto.input,modelo_grafo.input],outputs = modelo_combinado)\n",
        "\n",
        "modelo_final.compile(optimizer=optimizers.Adam(lr=1e-3),\n",
        "                     loss='binary_crossentropy',\n",
        "                     metrics=['acc'])\n",
        "\n",
        "history = modelo_final.fit(x=[text_trainX,num_trainX], y= y_train,\n",
        "                           validation_data=([text_testX,num_testX],y_test),\n",
        "                           epochs=50,verbose=1,batch_size=32,\n",
        "                           callbacks=[model_checkpoint_callback])\n",
        "\n",
        "modelo_final.load_weights(checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8rtnVFNSWyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Qjv-LILSYsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Si se observa buen comportamiento:\n",
        "\n",
        "modelo_final.fit(x=[input_text,numeric_train],y=encoded_Y,\n",
        "                 epochs=50,verbose=1,batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3ftpHkSScDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "preds = modelo_final.predict([challenge_input_text,numeric_challenge])\n",
        "\n",
        "challenge_labels = encoder.inverse_transform(preds)\n",
        "\n",
        "id_chal = []\n",
        "label_chal = []\n",
        "for x,y in zip(test_dataset[\"id\"],challenge_labels):\n",
        "    id_chal.append(x)\n",
        "    label_chal.append(y[0])\n",
        "\n",
        "\n",
        "sub = {\"label\":label_chal,\"id\":id_chal}\n",
        "\n",
        "submission = pd.DataFrame.from_dict(sub)\n",
        "submission.to_csv(\"SubmissionV9.csv\",index=False) #cambiar nombre cada vez que se haga submit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V737QbTLSdlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(modelo_final,show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}